{"cells":[{"cell_type":"markdown","metadata":{"id":"BpyKk2qGa-5L"},"source":["#Importo librerie"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5242,"status":"ok","timestamp":1622045731153,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"LGTWY6Buj5W0","outputId":"b809048c-19a0-4ec2-95c1-ec5b2047fd31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting keras-tuner\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n","\r\u001b[K     |█████▏                          | 10kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n","Collecting terminaltables\n","  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003ekeras-tuner) (2.4.7)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003ekeras-tuner) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003ekeras-tuner) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003ekeras-tuner) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003ekeras-tuner) (2020.12.5)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003ekeras-tuner) (1.0.1)\n","Building wheels for collected packages: keras-tuner, terminaltables\n","  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=45ec0ee27b2b13b4328e51a7b66ac901d2305a473ab4fa25364a504629ba4cf6\n","  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=04edf6777da207623df6c430e6e84b414db48cd8381f340c557c2f444ba2f993\n","  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n","Successfully built keras-tuner terminaltables\n","Installing collected packages: terminaltables, colorama, keras-tuner\n","Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"]}],"source":["!pip install keras-tuner"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":200,"status":"ok","timestamp":1622047040637,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"NBkgsz1maynQ"},"outputs":[],"source":["import pandas as pd \n","import numpy as np \n","import itertools\n","\n","from time import time\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, r2_score, precision_recall_fscore_support, mean_squared_error\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.utils import shuffle\n","\n","from imblearn.pipeline import Pipeline\n","from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n","from imblearn.under_sampling import RandomUnderSampler\n","from collections import Counter\n","\n","#import smogn\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LeakyReLU, Dropout, Conv1D, Flatten, MaxPooling1D, AveragePooling1D, SimpleRNN, LSTM\n","from keras.regularizers import l2, l1, l1_l2\n","from keras.constraints import max_norm\n","from keras.callbacks import EarlyStopping, History\n","from keras import optimizers\n","\n","from kerastuner import HyperModel\n","from kerastuner.tuners import Hyperband"]},{"cell_type":"markdown","metadata":{"id":"VIbG3QskuKmv"},"source":["#Definizione funzioni"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1622049740455,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"Yna6RhLsuNOg"},"outputs":[],"source":["# grafico matrice di confusione\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] \u003e thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1622049740455,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"dvgAzxJ6inCK"},"outputs":[],"source":["# stampa tempo trascorso\n","\n","def print_exec_time(start):\n","  print(\"Addestramento completato in %f secondi\" % (time()-start))"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1622049740456,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"vFFVEYeqm4A5"},"outputs":[],"source":["# funzione per creare un sotto-df con le classi target bilanciate, in modo che anche le classi della variabile specificata nel parametro col siano egualmente rappresentate in ciascuna classe target\n","\n","def undersample(df, label, col=None):\n","  hits = df[df[label] == 1]\n","  non_hits = df[df[label] == 0]\n","\n","  if(col != None):\n","\n","    non_hits_sampled_array = []\n","\n","    for a in non_hits[col].unique():\n","      n = hits[hits[col] == a].id.count()\n","      non_hits_sampled_array.append(non_hits[non_hits[col] == a].sample(n))\n","\n","    non_hits_sampled = pd.concat(non_hits_sampled_array)\n","\n","  else:\n","    non_hits_sampled = df[df[label] == 0].sample(hits.shape[0])\n","\n","  return pd.concat([hits,non_hits_sampled])"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1622049740456,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"lgG8iRZwirx3"},"outputs":[],"source":["def over_under_balancing(X, Y, oversample_ratio, oversample_algorithm):\n","  '''\n","  oversample_algorithm --\u003e [SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN]\n","  '''\n","  over = oversample_algorithm(sampling_strategy=oversample_ratio) # --\u003e genero nuovi esempi nella classe in minoranza (hit) in modo da portarla al (es.) 50% della classe maggioritaria (non-hit)\n","  under = RandomUnderSampler(sampling_strategy=1) # --\u003e rimuovo casualmente esempi dalla classe maggioritaria (non-hit) fino a portarla al 100% della classe minoritaria (hit)\n","  steps = [('o', over),('u', under)]\n","  pipeline = Pipeline(steps=steps)\n","\n","  X, Y = pipeline.fit_resample(X, Y)\n","  \n","  return X, Y"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1622049740457,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"Lqc5hh_Nivv2"},"outputs":[],"source":["# new_features_params\n","def insert_new_features_params(row, new_features_params):\n","    if(row.features == 'standard features'):\n","        return None\n","    else:\n","        return new_features_params"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1622049740457,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"xLd67SF1ixiB"},"outputs":[],"source":["# selezionare il numero di componenti principali per LDA\n","\n","def select_n_components(var_ratio, goal_var: float) -\u003e int:\n","    # Set initial variance explained so far\n","    total_variance = 0.0\n","    \n","    # Set initial number of features\n","    n_components = 0\n","    \n","    # For the explained variance of each feature:\n","    for explained_variance in var_ratio:\n","        \n","        # Add the explained variance to the total\n","        total_variance += explained_variance\n","        \n","        # Add one to the number of components\n","        n_components += 1\n","        \n","        # If we reach our goal level of explained variance\n","        if total_variance \u003e= goal_var:\n","            # End the loop\n","            break\n","            \n","    # Return the number of components\n","    return n_components"]},{"cell_type":"markdown","metadata":{"id":"733QnAej-lTM"},"source":["#Importo Dataset"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":2235,"status":"ok","timestamp":1622049743016,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"WaEaN0vLhYDe"},"outputs":[],"source":["!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":6261,"status":"ok","timestamp":1622049749273,"user":{"displayName":"Isacco Valsecchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsE3N_0rvi4i7PTUy9okHWPKo4CtX-Vq2O3tR8K8M=s64","userId":"14558454588425913231"},"user_tz":-120},"id":"kjehE21gtCz_"},"outputs":[],"source":["drive.CreateFile({'id':'1-0o81KniM9hNtC8zqBaYyQWAmGdTYSS5'}).GetContentFile('dataset_final_4.0.csv')\n","df = pd.read_csv(\"dataset_final_4.0.csv\").drop('Unnamed: 0',axis=1)"]},{"cell_type":"markdown","metadata":{"id":"kgsmWP6nbw5E"},"source":["#DL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"amqMVfqEhfYI"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_136\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_476 (Dense)            (None, 64)                5504      \n","_________________________________________________________________\n","dropout_340 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_477 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 5,569\n","Trainable params: 5,569\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","141/141 [==============================] - 1s 3ms/step - loss: 27.6747 - val_loss: 20.3290\n","Epoch 2/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.8498 - val_loss: 19.6735\n","Epoch 3/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.5114 - val_loss: 19.5008\n","Epoch 4/100\n","141/141 [==============================] - 0s 3ms/step - loss: 21.0807 - val_loss: 19.3246\n","Epoch 5/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.1018 - val_loss: 19.1417\n","Epoch 6/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.7750 - val_loss: 19.0460\n","Epoch 7/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.7363 - val_loss: 18.8743\n","Epoch 8/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.8104 - val_loss: 18.8469\n","Epoch 9/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.4344 - val_loss: 18.8119\n","Epoch 10/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.1797 - val_loss: 18.8097\n","Epoch 11/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.2030 - val_loss: 18.7707\n","Epoch 12/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.9571 - val_loss: 18.6901\n","Epoch 13/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.0809 - val_loss: 18.4857\n","Epoch 14/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.9513 - val_loss: 18.4989\n","Epoch 15/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.9603 - val_loss: 18.5789\n","Epoch 16/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.7733 - val_loss: 18.5402\n","Epoch 17/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.7480 - val_loss: 18.4977\n","Epoch 18/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.6340 - val_loss: 18.5628\n","Epoch 19/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.7397 - val_loss: 18.4727\n","Epoch 20/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.6562 - val_loss: 18.4917\n","Epoch 21/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4950 - val_loss: 18.3655\n","Epoch 22/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4221 - val_loss: 18.3120\n","Epoch 23/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.5373 - val_loss: 18.3347\n","Epoch 24/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.3293 - val_loss: 18.3674\n","Epoch 25/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.3074 - val_loss: 18.4218\n","Epoch 26/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4320 - val_loss: 18.3697\n","Epoch 27/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.2501 - val_loss: 18.3306\n","Epoch 28/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.2899 - val_loss: 18.3322\n","Epoch 29/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.2172 - val_loss: 18.2247\n","Epoch 30/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.2629 - val_loss: 18.2125\n","Epoch 31/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.0200 - val_loss: 18.3388\n","Epoch 32/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.1118 - val_loss: 18.2952\n","Epoch 33/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.2005 - val_loss: 18.2506\n","Epoch 34/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.0473 - val_loss: 18.2873\n","Epoch 35/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.1096 - val_loss: 18.1731\n","Epoch 36/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9533 - val_loss: 18.1648\n","Epoch 37/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9272 - val_loss: 18.1499\n","Epoch 38/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8681 - val_loss: 18.1146\n","Epoch 39/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.0238 - val_loss: 18.0887\n","Epoch 40/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7238 - val_loss: 18.0941\n","Epoch 41/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8859 - val_loss: 18.0865\n","Epoch 42/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8125 - val_loss: 18.2079\n","Epoch 43/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7321 - val_loss: 18.0320\n","Epoch 44/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7093 - val_loss: 17.9997\n","Epoch 45/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6076 - val_loss: 17.9566\n","Epoch 46/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7703 - val_loss: 18.0478\n","Epoch 47/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6758 - val_loss: 17.9466\n","Epoch 48/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6582 - val_loss: 18.0156\n","Epoch 49/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6909 - val_loss: 17.9280\n","Epoch 50/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5846 - val_loss: 17.9287\n","Epoch 51/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6873 - val_loss: 17.8735\n","Epoch 52/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6051 - val_loss: 17.9552\n","Epoch 53/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5214 - val_loss: 17.8800\n","Epoch 54/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5616 - val_loss: 17.9766\n","Epoch 55/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5899 - val_loss: 17.8714\n","Epoch 56/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5334 - val_loss: 17.9660\n","Epoch 57/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5508 - val_loss: 17.8355\n","Epoch 58/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6134 - val_loss: 17.8729\n","Epoch 59/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5200 - val_loss: 17.7744\n","Epoch 60/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5303 - val_loss: 17.7342\n","Epoch 61/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5038 - val_loss: 17.7613\n","Epoch 62/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.4880 - val_loss: 17.7863\n","Epoch 63/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.3273 - val_loss: 17.7779\n","Epoch 64/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5583 - val_loss: 17.7687\n","Epoch 65/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.3735 - val_loss: 17.7491\n","Epoch 66/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5384 - val_loss: 17.6611\n","Epoch 67/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.3373 - val_loss: 17.6911\n","Epoch 68/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.4167 - val_loss: 17.6480\n","Epoch 69/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.3434 - val_loss: 17.7053\n","Epoch 70/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.3597 - val_loss: 17.7232\n","Epoch 71/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2954 - val_loss: 17.5885\n","Epoch 72/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2242 - val_loss: 17.6475\n","Epoch 73/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2769 - val_loss: 17.7949\n","Epoch 74/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.4328 - val_loss: 17.5825\n","Epoch 75/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.3319 - val_loss: 17.6100\n","Epoch 76/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2330 - val_loss: 17.6271\n","Epoch 77/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.1824 - val_loss: 17.7158\n","Epoch 78/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.3779 - val_loss: 17.5040\n","Epoch 79/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2976 - val_loss: 17.5522\n","Epoch 80/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2144 - val_loss: 17.5300\n","Epoch 81/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.1565 - val_loss: 17.5623\n","Epoch 82/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2924 - val_loss: 17.5887\n","Epoch 83/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2746 - val_loss: 17.4937\n","Epoch 84/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.1428 - val_loss: 17.5358\n","Epoch 85/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2661 - val_loss: 17.5600\n","Epoch 86/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2970 - val_loss: 17.4649\n","Epoch 87/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.1551 - val_loss: 17.4989\n","Epoch 88/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2233 - val_loss: 17.4667\n","Epoch 89/100\n","141/141 [==============================] - 0s 2ms/step - loss: 17.9864 - val_loss: 17.5413\n","Epoch 90/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.0735 - val_loss: 17.4021\n","Epoch 91/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.1031 - val_loss: 17.3950\n","Epoch 92/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.2625 - val_loss: 17.4323\n","Epoch 93/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.0906 - val_loss: 17.4399\n","Epoch 94/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.3560 - val_loss: 17.3719\n","Epoch 95/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.1390 - val_loss: 17.3739\n","Epoch 96/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.1795 - val_loss: 17.4098\n","Epoch 97/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.0993 - val_loss: 17.4372\n","Epoch 98/100\n","141/141 [==============================] - 0s 2ms/step - loss: 17.9833 - val_loss: 17.3852\n","Epoch 99/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.0189 - val_loss: 17.2920\n","Epoch 100/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.0784 - val_loss: 17.4407\n","Addestramento completato in 30.334271 secondi\n","\n","\n","Model: \"sequential_137\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_478 (Dense)            (None, 1024)              88064     \n","_________________________________________________________________\n","dropout_341 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_479 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_342 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_480 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_343 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_481 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_344 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_482 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 389,375\n","Trainable params: 389,375\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","141/141 [==============================] - 1s 5ms/step - loss: 25.4570 - val_loss: 26.8712\n","Epoch 2/100\n","141/141 [==============================] - 0s 3ms/step - loss: 22.0760 - val_loss: 24.3404\n","Epoch 3/100\n","141/141 [==============================] - 0s 3ms/step - loss: 21.3137 - val_loss: 22.9122\n","Epoch 4/100\n","141/141 [==============================] - 0s 3ms/step - loss: 21.0258 - val_loss: 21.4565\n","Epoch 5/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.6757 - val_loss: 20.8694\n","Epoch 6/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.7110 - val_loss: 20.7753\n","Epoch 7/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.2579 - val_loss: 19.9557\n","Epoch 8/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.2707 - val_loss: 19.8510\n","Epoch 9/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.1734 - val_loss: 19.8554\n","Epoch 10/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.9733 - val_loss: 19.0842\n","Epoch 11/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.9651 - val_loss: 18.9334\n","Epoch 12/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.6980 - val_loss: 18.9247\n","Epoch 13/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.6354 - val_loss: 18.7237\n","Epoch 14/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.5292 - val_loss: 18.6565\n","Epoch 15/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.4335 - val_loss: 18.8141\n","Epoch 16/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.3514 - val_loss: 18.4956\n","Epoch 17/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.4401 - val_loss: 18.3668\n","Epoch 18/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.3671 - val_loss: 18.1582\n","Epoch 19/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.2007 - val_loss: 18.2758\n","Epoch 20/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.0540 - val_loss: 18.0739\n","Epoch 21/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.9189 - val_loss: 17.8482\n","Epoch 22/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7691 - val_loss: 18.2459\n","Epoch 23/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7529 - val_loss: 17.7247\n","Epoch 24/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6851 - val_loss: 17.8313\n","Epoch 25/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6991 - val_loss: 17.9271\n","Epoch 26/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7518 - val_loss: 18.0599\n","Epoch 27/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6333 - val_loss: 18.0409\n","Epoch 28/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4100 - val_loss: 17.6945\n","Epoch 29/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7757 - val_loss: 17.7965\n","Epoch 30/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4164 - val_loss: 18.0213\n","Epoch 31/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6942 - val_loss: 17.9464\n","Epoch 32/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5433 - val_loss: 17.7585\n","Epoch 33/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4232 - val_loss: 17.8188\n","Epoch 34/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4817 - val_loss: 17.5538\n","Epoch 35/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6530 - val_loss: 18.0908\n","Epoch 36/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4969 - val_loss: 17.9102\n","Epoch 37/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5372 - val_loss: 17.4678\n","Epoch 38/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5668 - val_loss: 17.6581\n","Epoch 39/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3769 - val_loss: 17.6027\n","Epoch 40/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4932 - val_loss: 17.5808\n","Epoch 41/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.2961 - val_loss: 17.7171\n","Epoch 42/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6212 - val_loss: 17.4166\n","Epoch 43/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5800 - val_loss: 17.5436\n","Epoch 44/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5083 - val_loss: 17.5649\n","Epoch 45/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7214 - val_loss: 17.6089\n","Epoch 46/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5717 - val_loss: 17.8965\n","Epoch 47/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4035 - val_loss: 17.7497\n","Epoch 48/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3208 - val_loss: 17.4504\n","Epoch 49/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5847 - val_loss: 17.6707\n","Addestramento completato in 22.039927 secondi\n","\n","\n","Model: \"sequential_138\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_483 (Dense)            (None, 64)                5504      \n","_________________________________________________________________\n","dropout_345 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_484 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 5,569\n","Trainable params: 5,569\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","12/12 [==============================] - 1s 18ms/step - loss: 37.4366 - val_loss: 28.1808\n","Epoch 2/100\n","12/12 [==============================] - 0s 4ms/step - loss: 28.5266 - val_loss: 21.8477\n","Epoch 3/100\n","12/12 [==============================] - 0s 4ms/step - loss: 23.8284 - val_loss: 19.5312\n","Epoch 4/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.8557 - val_loss: 19.2818\n","Epoch 5/100\n","12/12 [==============================] - 0s 3ms/step - loss: 23.1438 - val_loss: 19.1346\n","Epoch 6/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.8785 - val_loss: 19.1420\n","Epoch 7/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.6284 - val_loss: 18.9818\n","Epoch 8/100\n","12/12 [==============================] - 0s 3ms/step - loss: 21.3053 - val_loss: 18.7803\n","Epoch 9/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.8958 - val_loss: 18.6677\n","Epoch 10/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.2369 - val_loss: 18.5798\n","Epoch 11/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.0097 - val_loss: 18.5167\n","Epoch 12/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.0233 - val_loss: 18.4511\n","Epoch 13/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.4548 - val_loss: 18.3570\n","Epoch 14/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.7976 - val_loss: 18.2791\n","Epoch 15/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.7086 - val_loss: 18.1899\n","Epoch 16/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.4531 - val_loss: 18.1559\n","Epoch 17/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.8110 - val_loss: 18.1187\n","Epoch 18/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.3368 - val_loss: 18.1053\n","Epoch 19/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.7603 - val_loss: 18.0567\n","Epoch 20/100\n","12/12 [==============================] - 0s 3ms/step - loss: 21.2194 - val_loss: 18.0106\n","Epoch 21/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.0705 - val_loss: 17.9271\n","Epoch 22/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.9555 - val_loss: 17.9281\n","Epoch 23/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.5401 - val_loss: 17.8925\n","Epoch 24/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.7388 - val_loss: 17.8179\n","Epoch 25/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.1213 - val_loss: 17.7990\n","Epoch 26/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.0526 - val_loss: 17.7811\n","Epoch 27/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.9111 - val_loss: 17.7217\n","Epoch 28/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.1222 - val_loss: 17.7292\n","Epoch 29/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.1455 - val_loss: 17.7507\n","Epoch 30/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.0814 - val_loss: 17.7049\n","Epoch 31/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.2596 - val_loss: 17.6577\n","Epoch 32/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.3523 - val_loss: 17.6562\n","Epoch 33/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.3609 - val_loss: 17.6702\n","Epoch 34/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.6912 - val_loss: 17.5883\n","Epoch 35/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.5299 - val_loss: 17.6258\n","Epoch 36/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.9129 - val_loss: 17.5880\n","Epoch 37/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.9082 - val_loss: 17.5564\n","Epoch 38/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.0251 - val_loss: 17.5393\n","Epoch 39/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.9071 - val_loss: 17.5250\n","Epoch 40/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.4348 - val_loss: 17.5243\n","Epoch 41/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.8111 - val_loss: 17.5043\n","Epoch 42/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.2950 - val_loss: 17.5877\n","Epoch 43/100\n","12/12 [==============================] - 0s 3ms/step - loss: 20.0728 - val_loss: 17.5269\n","Epoch 44/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.4125 - val_loss: 17.4761\n","Epoch 45/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.8398 - val_loss: 17.4806\n","Epoch 46/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.0176 - val_loss: 17.5016\n","Epoch 47/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.4042 - val_loss: 17.4555\n","Epoch 48/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.2680 - val_loss: 17.4033\n","Epoch 49/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.0653 - val_loss: 17.4516\n","Epoch 50/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.0763 - val_loss: 17.4913\n","Epoch 51/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.0853 - val_loss: 17.4602\n","Epoch 52/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.5523 - val_loss: 17.4600\n","Epoch 53/100\n","12/12 [==============================] - 0s 3ms/step - loss: 19.5408 - val_loss: 17.4207\n","Epoch 54/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.9859 - val_loss: 17.4746\n","Epoch 55/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.0128 - val_loss: 17.3749\n","Epoch 56/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.5950 - val_loss: 17.3829\n","Epoch 57/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.9681 - val_loss: 17.4079\n","Epoch 58/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.0849 - val_loss: 17.3900\n","Epoch 59/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.6742 - val_loss: 17.3888\n","Epoch 60/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.8154 - val_loss: 17.3557\n","Epoch 61/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.7529 - val_loss: 17.3627\n","Epoch 62/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.5441 - val_loss: 17.3375\n","Epoch 63/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.7392 - val_loss: 17.3318\n","Epoch 64/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.9850 - val_loss: 17.3783\n","Epoch 65/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.2022 - val_loss: 17.3318\n","Addestramento completato in 3.885246 secondi\n","\n","\n","Model: \"sequential_139\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_485 (Dense)            (None, 1024)              88064     \n","_________________________________________________________________\n","dropout_346 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_486 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_347 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_487 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_348 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_488 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_349 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_489 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 389,375\n","Trainable params: 389,375\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","12/12 [==============================] - 1s 28ms/step - loss: 32.2029 - val_loss: 22.0512\n","Epoch 2/100\n","12/12 [==============================] - 0s 4ms/step - loss: 24.5335 - val_loss: 22.8250\n","Epoch 3/100\n","12/12 [==============================] - 0s 4ms/step - loss: 23.8603 - val_loss: 24.4311\n","Epoch 4/100\n","12/12 [==============================] - 0s 4ms/step - loss: 23.3564 - val_loss: 22.6797\n","Epoch 5/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.4155 - val_loss: 21.8745\n","Epoch 6/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.1626 - val_loss: 24.0704\n","Epoch 7/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.8357 - val_loss: 23.9186\n","Epoch 8/100\n","12/12 [==============================] - 0s 5ms/step - loss: 22.3046 - val_loss: 22.6229\n","Epoch 9/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.1290 - val_loss: 22.9233\n","Epoch 10/100\n","12/12 [==============================] - 0s 6ms/step - loss: 21.1298 - val_loss: 21.6850\n","Epoch 11/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.9451 - val_loss: 22.4089\n","Epoch 12/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.0629 - val_loss: 22.4834\n","Epoch 13/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.2298 - val_loss: 21.9771\n","Epoch 14/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.1303 - val_loss: 22.1126\n","Epoch 15/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.0552 - val_loss: 21.4951\n","Epoch 16/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.9281 - val_loss: 20.9188\n","Epoch 17/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.7663 - val_loss: 21.0702\n","Epoch 18/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.2455 - val_loss: 21.9673\n","Epoch 19/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.1878 - val_loss: 21.0750\n","Epoch 20/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.6337 - val_loss: 20.8051\n","Epoch 21/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.1707 - val_loss: 21.0440\n","Epoch 22/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.5131 - val_loss: 19.8014\n","Epoch 23/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.7512 - val_loss: 21.0784\n","Epoch 24/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.8041 - val_loss: 20.8126\n","Epoch 25/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.4145 - val_loss: 21.3299\n","Epoch 26/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.0170 - val_loss: 19.5929\n","Epoch 27/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.9283 - val_loss: 20.0784\n","Epoch 28/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.9587 - val_loss: 21.3014\n","Epoch 29/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.3579 - val_loss: 19.9848\n","Epoch 30/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.5888 - val_loss: 20.0058\n","Epoch 31/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.9404 - val_loss: 19.8130\n","Epoch 32/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.9855 - val_loss: 19.8379\n","Epoch 33/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.9809 - val_loss: 19.9482\n","Epoch 34/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.5892 - val_loss: 20.2443\n","Epoch 35/100\n","12/12 [==============================] - 0s 6ms/step - loss: 19.0634 - val_loss: 18.6326\n","Epoch 36/100\n","12/12 [==============================] - 0s 6ms/step - loss: 19.4612 - val_loss: 19.2527\n","Epoch 37/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.5672 - val_loss: 19.4463\n","Epoch 38/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.7008 - val_loss: 18.8524\n","Epoch 39/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.6494 - val_loss: 18.3061\n","Epoch 40/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.8127 - val_loss: 19.9424\n","Epoch 41/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.3144 - val_loss: 19.5401\n","Epoch 42/100\n","12/12 [==============================] - 0s 6ms/step - loss: 19.6532 - val_loss: 18.5568\n","Epoch 43/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.4812 - val_loss: 18.2788\n","Epoch 44/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.1127 - val_loss: 19.7807\n","Epoch 45/100\n","12/12 [==============================] - 0s 5ms/step - loss: 18.7641 - val_loss: 18.5768\n","Addestramento completato in 3.877006 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_140\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_490 (Dense)            (None, 64)                5504      \n","_________________________________________________________________\n","dropout_350 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_491 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 5,569\n","Trainable params: 5,569\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","15/15 [==============================] - 1s 16ms/step - loss: 37.4499 - val_loss: 25.2900\n","Epoch 2/100\n","15/15 [==============================] - 0s 3ms/step - loss: 27.3076 - val_loss: 21.4964\n","Epoch 3/100\n","15/15 [==============================] - 0s 3ms/step - loss: 25.1093 - val_loss: 21.1687\n","Epoch 4/100\n","15/15 [==============================] - 0s 3ms/step - loss: 24.1454 - val_loss: 20.9409\n","Epoch 5/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.8364 - val_loss: 20.7546\n","Epoch 6/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.9480 - val_loss: 20.5684\n","Epoch 7/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.7441 - val_loss: 20.4308\n","Epoch 8/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.8576 - val_loss: 20.3149\n","Epoch 9/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.7858 - val_loss: 20.2127\n","Epoch 10/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.9135 - val_loss: 20.1552\n","Epoch 11/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.4106 - val_loss: 20.0984\n","Epoch 12/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.4224 - val_loss: 20.0227\n","Epoch 13/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.4788 - val_loss: 19.9678\n","Epoch 14/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.9733 - val_loss: 19.9110\n","Epoch 15/100\n","15/15 [==============================] - 0s 5ms/step - loss: 21.6364 - val_loss: 19.8648\n","Epoch 16/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.6438 - val_loss: 19.8301\n","Epoch 17/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8112 - val_loss: 19.7820\n","Epoch 18/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7962 - val_loss: 19.7569\n","Epoch 19/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7448 - val_loss: 19.7303\n","Epoch 20/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.9718 - val_loss: 19.6971\n","Epoch 21/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7001 - val_loss: 19.6657\n","Epoch 22/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0525 - val_loss: 19.6388\n","Epoch 23/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3473 - val_loss: 19.6239\n","Epoch 24/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8352 - val_loss: 19.6101\n","Epoch 25/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0212 - val_loss: 19.6034\n","Epoch 26/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.9366 - val_loss: 19.5844\n","Epoch 27/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.1134 - val_loss: 19.5729\n","Epoch 28/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0398 - val_loss: 19.5472\n","Epoch 29/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.8226 - val_loss: 19.5409\n","Epoch 30/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.1287 - val_loss: 19.5282\n","Epoch 31/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.2777 - val_loss: 19.5177\n","Epoch 32/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3712 - val_loss: 19.5116\n","Addestramento completato in 2.641073 secondi\n","\n","\n","Model: \"sequential_141\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_492 (Dense)            (None, 1024)              88064     \n","_________________________________________________________________\n","dropout_351 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_493 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_352 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_494 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_353 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_495 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_354 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_496 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 389,375\n","Trainable params: 389,375\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","15/15 [==============================] - 1s 25ms/step - loss: 34.3919 - val_loss: 22.2911\n","Epoch 2/100\n","15/15 [==============================] - 0s 4ms/step - loss: 25.3485 - val_loss: 22.4496\n","Epoch 3/100\n","15/15 [==============================] - 0s 4ms/step - loss: 24.2977 - val_loss: 24.7774\n","Epoch 4/100\n","15/15 [==============================] - 0s 4ms/step - loss: 24.9506 - val_loss: 24.6565\n","Epoch 5/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.8290 - val_loss: 22.0993\n","Epoch 6/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.8777 - val_loss: 22.2749\n","Epoch 7/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.3753 - val_loss: 23.3386\n","Epoch 8/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.2062 - val_loss: 22.0764\n","Epoch 9/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.1432 - val_loss: 21.3080\n","Epoch 10/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.1096 - val_loss: 21.3917\n","Epoch 11/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.4140 - val_loss: 22.0551\n","Epoch 12/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.0476 - val_loss: 22.0307\n","Epoch 13/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.4766 - val_loss: 21.6466\n","Epoch 14/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.0558 - val_loss: 23.1435\n","Epoch 15/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.5586 - val_loss: 21.6350\n","Epoch 16/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.8050 - val_loss: 22.2781\n","Epoch 17/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.4946 - val_loss: 22.3945\n","Epoch 18/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0418 - val_loss: 22.0933\n","Epoch 19/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1748 - val_loss: 21.3769\n","Epoch 20/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.6819 - val_loss: 21.8493\n","Epoch 21/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1764 - val_loss: 21.4993\n","Epoch 22/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.9814 - val_loss: 21.5407\n","Epoch 23/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1215 - val_loss: 20.9102\n","Epoch 24/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7917 - val_loss: 20.9758\n","Epoch 25/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0564 - val_loss: 20.8931\n","Epoch 26/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.9259 - val_loss: 21.3103\n","Epoch 27/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7927 - val_loss: 20.8301\n","Epoch 28/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1741 - val_loss: 20.3749\n","Epoch 29/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0544 - val_loss: 19.9834\n","Epoch 30/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8382 - val_loss: 20.0365\n","Epoch 31/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7887 - val_loss: 19.9739\n","Epoch 32/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.6982 - val_loss: 20.7067\n","Epoch 33/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8493 - val_loss: 20.6954\n","Epoch 34/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7027 - val_loss: 20.3072\n","Epoch 35/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.5139 - val_loss: 19.5560\n","Epoch 36/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.1608 - val_loss: 19.9350\n","Epoch 37/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.6135 - val_loss: 20.2815\n","Epoch 38/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.6590 - val_loss: 20.3011\n","Epoch 39/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4016 - val_loss: 19.7204\n","Epoch 40/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.2813 - val_loss: 19.4261\n","Epoch 41/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.5629 - val_loss: 19.7688\n","Epoch 42/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4436 - val_loss: 19.6350\n","Epoch 43/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.3575 - val_loss: 19.4598\n","Epoch 44/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.3765 - val_loss: 19.4985\n","Epoch 45/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.2075 - val_loss: 18.9818\n","Epoch 46/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8211 - val_loss: 19.2174\n","Epoch 47/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.3076 - val_loss: 19.3414\n","Epoch 48/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2269 - val_loss: 19.3710\n","Epoch 49/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.1581 - val_loss: 19.2213\n","Epoch 50/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8560 - val_loss: 19.3890\n","Epoch 51/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.7911 - val_loss: 19.0973\n","Epoch 52/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3802 - val_loss: 19.0067\n","Epoch 53/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.1859 - val_loss: 18.8265\n","Epoch 54/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8853 - val_loss: 19.0155\n","Epoch 55/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4082 - val_loss: 18.6824\n","Epoch 56/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.9553 - val_loss: 18.8084\n","Epoch 57/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3564 - val_loss: 18.8752\n","Epoch 58/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.7744 - val_loss: 18.9967\n","Epoch 59/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8842 - val_loss: 18.6422\n","Epoch 60/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4810 - val_loss: 18.5668\n","Epoch 61/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3635 - val_loss: 18.6561\n","Epoch 62/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.5967 - val_loss: 18.6681\n","Epoch 63/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2189 - val_loss: 18.8137\n","Epoch 64/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8660 - val_loss: 18.7340\n","Epoch 65/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8626 - val_loss: 18.8374\n","Epoch 66/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3891 - val_loss: 18.9582\n","Epoch 67/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3635 - val_loss: 18.6765\n","Epoch 68/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3957 - val_loss: 18.6658\n","Epoch 69/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3647 - val_loss: 18.6203\n","Epoch 70/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.5153 - val_loss: 18.6582\n","Epoch 71/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0467 - val_loss: 18.6362\n","Epoch 72/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.5488 - val_loss: 18.7853\n","Epoch 73/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3988 - val_loss: 18.7010\n","Epoch 74/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.1927 - val_loss: 18.7574\n","Epoch 75/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4278 - val_loss: 18.8834\n","Epoch 76/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.6101 - val_loss: 18.6822\n","Epoch 77/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.8021 - val_loss: 18.8157\n","Epoch 78/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.7684 - val_loss: 18.7158\n","Epoch 79/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.9482 - val_loss: 18.5406\n","Epoch 80/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.7598 - val_loss: 18.4412\n","Epoch 81/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.8303 - val_loss: 18.6570\n","Epoch 82/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.8673 - val_loss: 18.5741\n","Epoch 83/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0863 - val_loss: 18.6334\n","Epoch 84/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0154 - val_loss: 18.4649\n","Epoch 85/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3859 - val_loss: 18.5977\n","Epoch 86/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.8571 - val_loss: 18.5108\n","Epoch 87/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0303 - val_loss: 18.6903\n","Epoch 88/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0706 - val_loss: 18.7471\n","Epoch 89/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2249 - val_loss: 18.5654\n","Epoch 90/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.1106 - val_loss: 18.4220\n","Epoch 91/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.1447 - val_loss: 18.4955\n","Epoch 92/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4364 - val_loss: 18.5870\n","Addestramento completato in 7.031951 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_142\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_497 (Dense)            (None, 64)                5504      \n","_________________________________________________________________\n","dropout_355 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_498 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 5,569\n","Trainable params: 5,569\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","15/15 [==============================] - 1s 14ms/step - loss: 44.4439 - val_loss: 32.4895\n","Epoch 2/100\n","15/15 [==============================] - 0s 3ms/step - loss: 31.4397 - val_loss: 24.6017\n","Epoch 3/100\n","15/15 [==============================] - 0s 3ms/step - loss: 26.7910 - val_loss: 22.4075\n","Epoch 4/100\n","15/15 [==============================] - 0s 3ms/step - loss: 25.4547 - val_loss: 21.9096\n","Epoch 5/100\n","15/15 [==============================] - 0s 3ms/step - loss: 24.9552 - val_loss: 21.6950\n","Epoch 6/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.7399 - val_loss: 21.1652\n","Epoch 7/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.0765 - val_loss: 20.6566\n","Epoch 8/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.6155 - val_loss: 20.3948\n","Epoch 9/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.7555 - val_loss: 20.2267\n","Epoch 10/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8587 - val_loss: 20.0612\n","Epoch 11/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.5177 - val_loss: 19.8743\n","Epoch 12/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7966 - val_loss: 19.7867\n","Epoch 13/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.4520 - val_loss: 19.7877\n","Epoch 14/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.7449 - val_loss: 19.5568\n","Epoch 15/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7764 - val_loss: 19.6193\n","Epoch 16/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8197 - val_loss: 19.5593\n","Epoch 17/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7103 - val_loss: 19.4547\n","Epoch 18/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8544 - val_loss: 19.4299\n","Epoch 19/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.6734 - val_loss: 19.3538\n","Epoch 20/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.9060 - val_loss: 19.3001\n","Epoch 21/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.4811 - val_loss: 19.2851\n","Epoch 22/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0930 - val_loss: 19.2049\n","Epoch 23/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.2199 - val_loss: 19.1765\n","Epoch 24/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.2743 - val_loss: 19.1215\n","Epoch 25/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.4868 - val_loss: 19.0585\n","Epoch 26/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3486 - val_loss: 19.2210\n","Epoch 27/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.4656 - val_loss: 19.0070\n","Epoch 28/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.9680 - val_loss: 18.9342\n","Epoch 29/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.2658 - val_loss: 18.9781\n","Epoch 30/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0062 - val_loss: 19.0128\n","Epoch 31/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.1801 - val_loss: 18.9586\n","Epoch 32/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0314 - val_loss: 18.8739\n","Epoch 33/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.7156 - val_loss: 18.8874\n","Epoch 34/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3436 - val_loss: 19.0032\n","Epoch 35/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.7241 - val_loss: 18.7451\n","Epoch 36/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0354 - val_loss: 18.8690\n","Epoch 37/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0857 - val_loss: 18.7256\n","Epoch 38/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.6867 - val_loss: 18.7722\n","Epoch 39/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.3104 - val_loss: 18.6788\n","Epoch 40/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.6608 - val_loss: 18.6751\n","Epoch 41/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0874 - val_loss: 18.7943\n","Addestramento completato in 2.748083 secondi\n","\n","\n","Model: \"sequential_143\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_499 (Dense)            (None, 1024)              88064     \n","_________________________________________________________________\n","dropout_356 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_500 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_357 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_501 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_358 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_502 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_359 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_503 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 389,375\n","Trainable params: 389,375\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","15/15 [==============================] - 1s 24ms/step - loss: 32.7668 - val_loss: 27.3230\n","Epoch 2/100\n","15/15 [==============================] - 0s 4ms/step - loss: 25.3044 - val_loss: 25.8520\n","Epoch 3/100\n","15/15 [==============================] - 0s 4ms/step - loss: 24.8537 - val_loss: 25.5943\n","Epoch 4/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.8126 - val_loss: 26.8143\n","Epoch 5/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.5129 - val_loss: 26.1966\n","Epoch 6/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.8566 - val_loss: 25.7601\n","Epoch 7/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.7110 - val_loss: 25.8755\n","Epoch 8/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.9544 - val_loss: 24.7291\n","Epoch 9/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.3097 - val_loss: 24.0998\n","Epoch 10/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.2887 - val_loss: 23.4011\n","Epoch 11/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.8326 - val_loss: 23.6440\n","Epoch 12/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.7310 - val_loss: 22.9742\n","Epoch 13/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.7731 - val_loss: 23.5336\n","Epoch 14/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.3702 - val_loss: 23.5992\n","Epoch 15/100\n","15/15 [==============================] - 0s 5ms/step - loss: 21.4331 - val_loss: 23.4055\n","Epoch 16/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8914 - val_loss: 22.6544\n","Epoch 17/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8429 - val_loss: 20.2353\n","Epoch 18/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8341 - val_loss: 21.1433\n","Epoch 19/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8762 - val_loss: 21.0810\n","Epoch 20/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.8893 - val_loss: 20.8775\n","Epoch 21/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0045 - val_loss: 21.1972\n","Epoch 22/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0896 - val_loss: 21.4994\n","Epoch 23/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7456 - val_loss: 21.9242\n","Epoch 24/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4564 - val_loss: 21.3957\n","Epoch 25/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.2845 - val_loss: 20.8693\n","Epoch 26/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.1799 - val_loss: 20.1891\n","Epoch 27/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4630 - val_loss: 21.3939\n","Epoch 28/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4726 - val_loss: 21.2157\n","Epoch 29/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.9028 - val_loss: 20.0940\n","Epoch 30/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.9700 - val_loss: 20.3845\n","Epoch 31/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.6907 - val_loss: 20.3193\n","Epoch 32/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.5866 - val_loss: 19.1347\n","Epoch 33/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.3489 - val_loss: 19.4447\n","Epoch 34/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8481 - val_loss: 19.0390\n","Epoch 35/100\n","15/15 [==============================] - 0s 5ms/step - loss: 19.4909 - val_loss: 20.1128\n","Epoch 36/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.0530 - val_loss: 19.6418\n","Epoch 37/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2825 - val_loss: 19.2037\n","Epoch 38/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.0751 - val_loss: 19.2526\n","Epoch 39/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8877 - val_loss: 19.2182\n","Epoch 40/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.6473 - val_loss: 19.6743\n","Epoch 41/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.7593 - val_loss: 19.9352\n","Epoch 42/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.2166 - val_loss: 19.3126\n","Epoch 43/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4518 - val_loss: 19.3876\n","Epoch 44/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.6273 - val_loss: 18.8745\n","Epoch 45/100\n","15/15 [==============================] - 0s 5ms/step - loss: 19.7953 - val_loss: 19.0693\n","Epoch 46/100\n","15/15 [==============================] - 0s 5ms/step - loss: 18.9997 - val_loss: 18.5026\n","Epoch 47/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.7284 - val_loss: 18.1082\n","Epoch 48/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.1562 - val_loss: 18.3178\n","Epoch 49/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3091 - val_loss: 18.7197\n","Epoch 50/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3088 - val_loss: 19.0956\n","Epoch 51/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2719 - val_loss: 18.9772\n","Epoch 52/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.7066 - val_loss: 18.4659\n","Epoch 53/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.5730 - val_loss: 17.9105\n","Epoch 54/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.9569 - val_loss: 18.2504\n","Epoch 55/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.5823 - val_loss: 18.8509\n","Epoch 56/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.1889 - val_loss: 17.3645\n","Epoch 57/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2135 - val_loss: 17.9005\n","Epoch 58/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.1866 - val_loss: 18.6715\n","Epoch 59/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4268 - val_loss: 18.4614\n","Epoch 60/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.7665 - val_loss: 18.3667\n","Epoch 61/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0133 - val_loss: 18.0656\n","Epoch 62/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3867 - val_loss: 18.5222\n","Epoch 63/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3362 - val_loss: 18.1535\n","Epoch 64/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.8167 - val_loss: 17.6561\n","Epoch 65/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.6080 - val_loss: 17.6102\n","Epoch 66/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.6820 - val_loss: 17.4471\n","Epoch 67/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2358 - val_loss: 17.1982\n","Epoch 68/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.6715 - val_loss: 17.2148\n","Epoch 69/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.9219 - val_loss: 17.8524\n","Epoch 70/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.4368 - val_loss: 17.4874\n","Epoch 71/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.8784 - val_loss: 17.7182\n","Epoch 72/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0612 - val_loss: 18.0303\n","Epoch 73/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.5813 - val_loss: 17.6023\n","Epoch 74/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.1292 - val_loss: 17.2788\n","Epoch 75/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.4344 - val_loss: 17.4387\n","Epoch 76/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.4503 - val_loss: 17.3087\n","Epoch 77/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.7485 - val_loss: 17.3797\n","Epoch 78/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.1786 - val_loss: 17.8134\n","Epoch 79/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.3341 - val_loss: 17.2671\n","Epoch 80/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.3917 - val_loss: 17.6663\n","Epoch 81/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.4113 - val_loss: 17.1743\n","Epoch 82/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.7097 - val_loss: 17.2460\n","Epoch 83/100\n","15/15 [==============================] - 0s 4ms/step - loss: 17.9518 - val_loss: 17.1137\n","Epoch 84/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.1421 - val_loss: 17.1224\n","Epoch 85/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.2912 - val_loss: 17.3390\n","Epoch 86/100\n","15/15 [==============================] - 0s 4ms/step - loss: 17.8837 - val_loss: 17.4026\n","Epoch 87/100\n","15/15 [==============================] - 0s 4ms/step - loss: 17.8311 - val_loss: 17.6359\n","Epoch 88/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.4439 - val_loss: 17.4514\n","Epoch 89/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.6495 - val_loss: 17.1595\n","Epoch 90/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.4068 - val_loss: 17.4376\n","Epoch 91/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.4639 - val_loss: 17.1672\n","Epoch 92/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.2257 - val_loss: 17.0750\n","Epoch 93/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.1734 - val_loss: 17.5447\n","Epoch 94/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.1954 - val_loss: 17.0652\n","Epoch 95/100\n","15/15 [==============================] - 0s 4ms/step - loss: 17.8250 - val_loss: 17.4901\n","Epoch 96/100\n","15/15 [==============================] - 0s 4ms/step - loss: 18.2212 - val_loss: 17.0419\n","Addestramento completato in 7.583459 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_144\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_504 (Dense)            (None, 64)                5504      \n","_________________________________________________________________\n","dropout_360 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_505 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 5,569\n","Trainable params: 5,569\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","19/19 [==============================] - 1s 12ms/step - loss: 44.4882 - val_loss: 29.5112\n","Epoch 2/100\n","19/19 [==============================] - 0s 3ms/step - loss: 29.0572 - val_loss: 22.9671\n","Epoch 3/100\n","19/19 [==============================] - 0s 3ms/step - loss: 26.4243 - val_loss: 21.8752\n","Epoch 4/100\n","19/19 [==============================] - 0s 3ms/step - loss: 25.2930 - val_loss: 21.5861\n","Epoch 5/100\n","19/19 [==============================] - 0s 3ms/step - loss: 24.4118 - val_loss: 21.1735\n","Epoch 6/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.7552 - val_loss: 20.8089\n","Epoch 7/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.5303 - val_loss: 20.7498\n","Epoch 8/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.4015 - val_loss: 20.3816\n","Epoch 9/100\n","19/19 [==============================] - 0s 4ms/step - loss: 23.7716 - val_loss: 20.3529\n","Epoch 10/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.8830 - val_loss: 20.1122\n","Epoch 11/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.9828 - val_loss: 20.0458\n","Epoch 12/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.7472 - val_loss: 20.0256\n","Epoch 13/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.8536 - val_loss: 19.9163\n","Epoch 14/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.7593 - val_loss: 19.8581\n","Epoch 15/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.1054 - val_loss: 19.7710\n","Epoch 16/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.5241 - val_loss: 19.7817\n","Epoch 17/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.3128 - val_loss: 19.6130\n","Epoch 18/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.7131 - val_loss: 19.6340\n","Epoch 19/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.2921 - val_loss: 19.5635\n","Epoch 20/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.2418 - val_loss: 19.5173\n","Epoch 21/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.1293 - val_loss: 19.5246\n","Epoch 22/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.8215 - val_loss: 19.5496\n","Epoch 23/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.0031 - val_loss: 19.4984\n","Epoch 24/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.0522 - val_loss: 19.4995\n","Epoch 25/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.5598 - val_loss: 19.4334\n","Epoch 26/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.7990 - val_loss: 19.3902\n","Epoch 27/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.4093 - val_loss: 19.4153\n","Epoch 28/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.3189 - val_loss: 19.4182\n","Epoch 29/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.8954 - val_loss: 19.2833\n","Epoch 30/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.8407 - val_loss: 19.3806\n","Epoch 31/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.9744 - val_loss: 19.3312\n","Epoch 32/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.4678 - val_loss: 19.2956\n","Epoch 33/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.7748 - val_loss: 19.3422\n","Epoch 34/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.7094 - val_loss: 19.2207\n","Epoch 35/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.4722 - val_loss: 19.2234\n","Epoch 36/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.5921 - val_loss: 19.2211\n","Epoch 37/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.3165 - val_loss: 19.1904\n","Epoch 38/100\n","19/19 [==============================] - 0s 3ms/step - loss: 20.9703 - val_loss: 19.2462\n","Epoch 39/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.7130 - val_loss: 19.1774\n","Epoch 40/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.6026 - val_loss: 19.1328\n","Epoch 41/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.5535 - val_loss: 19.0983\n","Epoch 42/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.4325 - val_loss: 19.1310\n","Epoch 43/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.5269 - val_loss: 19.1657\n","Epoch 44/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.8148 - val_loss: 19.1212\n","Epoch 45/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.5288 - val_loss: 19.1597\n","Epoch 46/100\n","19/19 [==============================] - 0s 3ms/step - loss: 20.7683 - val_loss: 19.0255\n","Epoch 47/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.6463 - val_loss: 19.0526\n","Epoch 48/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.8527 - val_loss: 19.0898\n","Epoch 49/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.8216 - val_loss: 19.1822\n","Epoch 50/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.6096 - val_loss: 19.0103\n","Epoch 51/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.2847 - val_loss: 19.0268\n","Epoch 52/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.8226 - val_loss: 19.0556\n","Epoch 53/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.2005 - val_loss: 18.9299\n","Epoch 54/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.3566 - val_loss: 18.9973\n","Epoch 55/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.0706 - val_loss: 18.9764\n","Epoch 56/100\n","19/19 [==============================] - 0s 3ms/step - loss: 20.8250 - val_loss: 18.9636\n","Addestramento completato in 3.976187 secondi\n","\n","\n","Model: \"sequential_145\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_506 (Dense)            (None, 1024)              88064     \n","_________________________________________________________________\n","dropout_361 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_507 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_362 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_508 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_363 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_509 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_364 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_510 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 389,375\n","Trainable params: 389,375\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","19/19 [==============================] - 1s 18ms/step - loss: 34.9685 - val_loss: 26.9171\n","Epoch 2/100\n","19/19 [==============================] - 0s 4ms/step - loss: 25.7973 - val_loss: 24.4118\n","Epoch 3/100\n","19/19 [==============================] - 0s 4ms/step - loss: 24.5615 - val_loss: 22.7866\n","Epoch 4/100\n","19/19 [==============================] - 0s 4ms/step - loss: 24.1832 - val_loss: 23.4742\n","Epoch 5/100\n","19/19 [==============================] - 0s 4ms/step - loss: 23.6032 - val_loss: 23.8141\n","Epoch 6/100\n","19/19 [==============================] - 0s 4ms/step - loss: 23.0902 - val_loss: 23.1711\n","Epoch 7/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.7593 - val_loss: 22.2303\n","Epoch 8/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.3751 - val_loss: 21.3620\n","Epoch 9/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.3428 - val_loss: 21.8434\n","Epoch 10/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.5570 - val_loss: 21.5952\n","Epoch 11/100\n","19/19 [==============================] - 0s 5ms/step - loss: 22.1976 - val_loss: 22.0057\n","Epoch 12/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.0402 - val_loss: 21.5987\n","Epoch 13/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.7400 - val_loss: 20.9221\n","Epoch 14/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.9162 - val_loss: 22.5604\n","Epoch 15/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.8336 - val_loss: 21.5291\n","Epoch 16/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.3357 - val_loss: 22.3142\n","Epoch 17/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.8083 - val_loss: 21.0856\n","Epoch 18/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.6411 - val_loss: 20.9291\n","Epoch 19/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.1974 - val_loss: 21.8886\n","Epoch 20/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.1272 - val_loss: 21.8803\n","Epoch 21/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.6499 - val_loss: 20.5418\n","Epoch 22/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.4321 - val_loss: 19.6424\n","Epoch 23/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.6500 - val_loss: 19.8059\n","Epoch 24/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.9585 - val_loss: 20.1483\n","Epoch 25/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.7763 - val_loss: 20.3161\n","Epoch 26/100\n","19/19 [==============================] - 0s 5ms/step - loss: 20.8642 - val_loss: 20.8294\n","Epoch 27/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.8550 - val_loss: 20.7113\n","Epoch 28/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.2352 - val_loss: 20.1896\n","Epoch 29/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.2686 - val_loss: 20.1475\n","Epoch 30/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.9490 - val_loss: 19.6345\n","Epoch 31/100\n","19/19 [==============================] - 0s 3ms/step - loss: 19.8102 - val_loss: 19.4524\n","Epoch 32/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.0497 - val_loss: 19.6854\n","Epoch 33/100\n","19/19 [==============================] - 0s 3ms/step - loss: 20.7723 - val_loss: 19.8651\n","Epoch 34/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.3529 - val_loss: 19.2468\n","Epoch 35/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.8578 - val_loss: 19.5450\n","Epoch 36/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.3462 - val_loss: 19.3908\n","Epoch 37/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.1818 - val_loss: 19.1573\n","Epoch 38/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.8735 - val_loss: 19.7142\n","Epoch 39/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.8552 - val_loss: 19.9517\n","Epoch 40/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.2154 - val_loss: 18.9583\n","Epoch 41/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.4621 - val_loss: 18.5078\n","Epoch 42/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.0509 - val_loss: 18.7084\n","Epoch 43/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.7956 - val_loss: 18.9201\n","Epoch 44/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.2080 - val_loss: 18.9105\n","Epoch 45/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.1634 - val_loss: 19.1221\n","Epoch 46/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.9967 - val_loss: 19.0318\n","Epoch 47/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.8147 - val_loss: 18.4027\n","Epoch 48/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.0040 - val_loss: 19.0168\n","Epoch 49/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.1151 - val_loss: 18.7255\n","Epoch 50/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.3622 - val_loss: 18.4951\n","Epoch 51/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.7799 - val_loss: 18.8119\n","Epoch 52/100\n","19/19 [==============================] - 0s 5ms/step - loss: 19.9002 - val_loss: 18.5346\n","Epoch 53/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.6599 - val_loss: 18.6939\n","Epoch 54/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.3527 - val_loss: 18.4068\n","Epoch 55/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.3757 - val_loss: 18.4095\n","Epoch 56/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.7494 - val_loss: 18.6088\n","Epoch 57/100\n","19/19 [==============================] - 0s 3ms/step - loss: 19.6955 - val_loss: 18.5296\n","Epoch 58/100\n","19/19 [==============================] - 0s 3ms/step - loss: 19.3074 - val_loss: 18.1591\n","Epoch 59/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.4234 - val_loss: 18.2256\n","Epoch 60/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.8949 - val_loss: 18.2922\n","Epoch 61/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.4624 - val_loss: 18.0415\n","Epoch 62/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.6804 - val_loss: 18.2930\n","Epoch 63/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.4022 - val_loss: 18.1332\n","Epoch 64/100\n","19/19 [==============================] - 0s 5ms/step - loss: 19.4369 - val_loss: 18.4314\n","Epoch 65/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.6616 - val_loss: 17.9553\n","Epoch 66/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.5497 - val_loss: 18.0785\n","Epoch 67/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.2929 - val_loss: 18.4365\n","Epoch 68/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.5811 - val_loss: 18.0608\n","Epoch 69/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.9695 - val_loss: 17.9390\n","Epoch 70/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.1220 - val_loss: 18.0539\n","Epoch 71/100\n","19/19 [==============================] - 0s 5ms/step - loss: 19.1196 - val_loss: 18.1975\n","Epoch 72/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.7671 - val_loss: 18.0473\n","Epoch 73/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.1982 - val_loss: 17.8876\n","Epoch 74/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.9129 - val_loss: 18.0855\n","Epoch 75/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.6357 - val_loss: 18.2736\n","Epoch 76/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.1250 - val_loss: 17.9749\n","Epoch 77/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.8227 - val_loss: 18.0585\n","Epoch 78/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.9051 - val_loss: 18.1527\n","Epoch 79/100\n","19/19 [==============================] - 0s 5ms/step - loss: 18.3481 - val_loss: 17.7475\n","Epoch 80/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.3917 - val_loss: 18.0275\n","Epoch 81/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.1610 - val_loss: 17.9916\n","Epoch 82/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.9988 - val_loss: 18.0728\n","Epoch 83/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.6086 - val_loss: 17.7877\n","Epoch 84/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.4589 - val_loss: 18.2513\n","Epoch 85/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.8096 - val_loss: 18.0266\n","Epoch 86/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.5282 - val_loss: 18.2713\n","Epoch 87/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.1013 - val_loss: 17.8130\n","Epoch 88/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.0717 - val_loss: 17.8640\n","Epoch 89/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.5718 - val_loss: 18.2521\n","Epoch 90/100\n","19/19 [==============================] - 0s 5ms/step - loss: 18.8196 - val_loss: 18.0794\n","Epoch 91/100\n","19/19 [==============================] - 0s 5ms/step - loss: 18.7325 - val_loss: 17.8726\n","Epoch 92/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.5752 - val_loss: 17.7334\n","Epoch 93/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.1187 - val_loss: 17.7317\n","Epoch 94/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.9856 - val_loss: 17.6971\n","Epoch 95/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.6051 - val_loss: 18.2297\n","Epoch 96/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.4392 - val_loss: 18.0337\n","Epoch 97/100\n","19/19 [==============================] - 0s 4ms/step - loss: 19.0040 - val_loss: 17.8002\n","Epoch 98/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.4275 - val_loss: 17.7724\n","Epoch 99/100\n","19/19 [==============================] - 0s 5ms/step - loss: 18.3034 - val_loss: 18.1974\n","Epoch 100/100\n","19/19 [==============================] - 0s 4ms/step - loss: 18.3644 - val_loss: 18.0220\n","Addestramento completato in 11.036974 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_146\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_511 (Dense)            (None, 64)                5504      \n","_________________________________________________________________\n","dropout_365 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_512 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 5,569\n","Trainable params: 5,569\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","26/26 [==============================] - 1s 9ms/step - loss: 32.1476 - val_loss: 22.2149\n","Epoch 2/100\n","26/26 [==============================] - 0s 3ms/step - loss: 24.5909 - val_loss: 21.5225\n","Epoch 3/100\n","26/26 [==============================] - 0s 2ms/step - loss: 24.2116 - val_loss: 21.2665\n","Epoch 4/100\n","26/26 [==============================] - 0s 3ms/step - loss: 23.2153 - val_loss: 20.9214\n","Epoch 5/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.6986 - val_loss: 20.8151\n","Epoch 6/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.8091 - val_loss: 20.7252\n","Epoch 7/100\n","26/26 [==============================] - 0s 3ms/step - loss: 23.0088 - val_loss: 20.5961\n","Epoch 8/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.6374 - val_loss: 20.6803\n","Epoch 9/100\n","26/26 [==============================] - 0s 2ms/step - loss: 22.3270 - val_loss: 20.4935\n","Epoch 10/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.9198 - val_loss: 20.5024\n","Epoch 11/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.2469 - val_loss: 20.4253\n","Epoch 12/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.1005 - val_loss: 20.3820\n","Epoch 13/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.8896 - val_loss: 20.3572\n","Epoch 14/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.8252 - val_loss: 20.3386\n","Epoch 15/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.6658 - val_loss: 20.2744\n","Epoch 16/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.4941 - val_loss: 20.3774\n","Epoch 17/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.5316 - val_loss: 20.2184\n","Epoch 18/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.7771 - val_loss: 20.1477\n","Epoch 19/100\n","26/26 [==============================] - 0s 2ms/step - loss: 22.0895 - val_loss: 20.1746\n","Epoch 20/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.5918 - val_loss: 20.1021\n","Epoch 21/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.6490 - val_loss: 20.1371\n","Epoch 22/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.2172 - val_loss: 20.0322\n","Epoch 23/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.4828 - val_loss: 20.0928\n","Epoch 24/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.3326 - val_loss: 20.0115\n","Epoch 25/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.2798 - val_loss: 19.9876\n","Epoch 26/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.6439 - val_loss: 19.9819\n","Epoch 27/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.4502 - val_loss: 19.9892\n","Epoch 28/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.2639 - val_loss: 19.9960\n","Epoch 29/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.9388 - val_loss: 19.9135\n","Epoch 30/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.3122 - val_loss: 19.8296\n","Epoch 31/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.2307 - val_loss: 19.8745\n","Epoch 32/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.8605 - val_loss: 19.9608\n","Epoch 33/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.3349 - val_loss: 19.7502\n","Epoch 34/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.1220 - val_loss: 19.8956\n","Epoch 35/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.1388 - val_loss: 19.8106\n","Epoch 36/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.9233 - val_loss: 19.7248\n","Epoch 37/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.9353 - val_loss: 19.7280\n","Epoch 38/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.2746 - val_loss: 19.7031\n","Epoch 39/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.4974 - val_loss: 19.6673\n","Epoch 40/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.8623 - val_loss: 19.6558\n","Epoch 41/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.6690 - val_loss: 19.6518\n","Epoch 42/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.5483 - val_loss: 19.7210\n","Epoch 43/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.4278 - val_loss: 19.6453\n","Epoch 44/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.2713 - val_loss: 19.6055\n","Epoch 45/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.9036 - val_loss: 19.6112\n","Epoch 46/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.6868 - val_loss: 19.5716\n","Epoch 47/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.8898 - val_loss: 19.5905\n","Epoch 48/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.6920 - val_loss: 19.6256\n","Epoch 49/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.5901 - val_loss: 19.5777\n","Epoch 50/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.2144 - val_loss: 19.4689\n","Epoch 51/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.6617 - val_loss: 19.4621\n","Epoch 52/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.4761 - val_loss: 19.4981\n","Epoch 53/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.4240 - val_loss: 19.4023\n","Epoch 54/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.5362 - val_loss: 19.4541\n","Epoch 55/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.6994 - val_loss: 19.4447\n","Epoch 56/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.4243 - val_loss: 19.4136\n","Epoch 57/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.4702 - val_loss: 19.3538\n","Epoch 58/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.6762 - val_loss: 19.4162\n","Epoch 59/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.4633 - val_loss: 19.2769\n","Epoch 60/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.4836 - val_loss: 19.4908\n","Epoch 61/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.4675 - val_loss: 19.3654\n","Epoch 62/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.5005 - val_loss: 19.3296\n","Epoch 63/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.0370 - val_loss: 19.2649\n","Epoch 64/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.0749 - val_loss: 19.2992\n","Epoch 65/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.9394 - val_loss: 19.2203\n","Epoch 66/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.9621 - val_loss: 19.2498\n","Epoch 67/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.2137 - val_loss: 19.2406\n","Epoch 68/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.9667 - val_loss: 19.1692\n","Epoch 69/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.2166 - val_loss: 19.2073\n","Epoch 70/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.9384 - val_loss: 19.1160\n","Epoch 71/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.9504 - val_loss: 19.1520\n","Epoch 72/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.8918 - val_loss: 19.1002\n","Epoch 73/100\n","26/26 [==============================] - 0s 2ms/step - loss: 20.1715 - val_loss: 19.0689\n","Epoch 74/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.1227 - val_loss: 19.0609\n","Epoch 75/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.9172 - val_loss: 19.0762\n","Epoch 76/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.9816 - val_loss: 19.0479\n","Epoch 77/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.6978 - val_loss: 19.1146\n","Epoch 78/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.9278 - val_loss: 19.0238\n","Epoch 79/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.0146 - val_loss: 19.0536\n","Epoch 80/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.7524 - val_loss: 19.0816\n","Epoch 81/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.1409 - val_loss: 19.1334\n","Epoch 82/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.1280 - val_loss: 18.9689\n","Epoch 83/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.8474 - val_loss: 18.9644\n","Epoch 84/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.6533 - val_loss: 18.9378\n","Epoch 85/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.3675 - val_loss: 18.9559\n","Epoch 86/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.8157 - val_loss: 18.8876\n","Epoch 87/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7431 - val_loss: 19.0432\n","Epoch 88/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.5889 - val_loss: 18.8687\n","Epoch 89/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.5801 - val_loss: 18.9169\n","Epoch 90/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.6105 - val_loss: 18.8387\n","Epoch 91/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.6400 - val_loss: 18.8556\n","Epoch 92/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.4981 - val_loss: 18.9135\n","Epoch 93/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.6780 - val_loss: 18.8885\n","Epoch 94/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.4315 - val_loss: 18.9266\n","Epoch 95/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.5204 - val_loss: 18.8243\n","Epoch 96/100\n","26/26 [==============================] - 0s 2ms/step - loss: 19.6249 - val_loss: 18.8963\n","Epoch 97/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.4882 - val_loss: 18.7998\n","Epoch 98/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.3409 - val_loss: 18.7780\n","Epoch 99/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.5706 - val_loss: 18.7987\n","Epoch 100/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.3903 - val_loss: 18.7896\n","Addestramento completato in 8.236666 secondi\n","\n","\n","Model: \"sequential_147\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_513 (Dense)            (None, 1024)              88064     \n","_________________________________________________________________\n","dropout_366 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_514 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_367 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_515 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_368 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_516 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_369 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_517 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 389,375\n","Trainable params: 389,375\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","26/26 [==============================] - 1s 15ms/step - loss: 33.3102 - val_loss: 28.3906\n","Epoch 2/100\n","26/26 [==============================] - 0s 4ms/step - loss: 25.5379 - val_loss: 27.8251\n","Epoch 3/100\n","26/26 [==============================] - 0s 4ms/step - loss: 23.7862 - val_loss: 25.1589\n","Epoch 4/100\n","26/26 [==============================] - 0s 4ms/step - loss: 23.1166 - val_loss: 27.7721\n","Epoch 5/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.9205 - val_loss: 24.4633\n","Epoch 6/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.6074 - val_loss: 25.8734\n","Epoch 7/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.9428 - val_loss: 25.6872\n","Epoch 8/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.0658 - val_loss: 24.4174\n","Epoch 9/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.0376 - val_loss: 24.4968\n","Epoch 10/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.5901 - val_loss: 24.4736\n","Epoch 11/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.8749 - val_loss: 24.4475\n","Epoch 12/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.9919 - val_loss: 21.8588\n","Epoch 13/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.6358 - val_loss: 23.6156\n","Epoch 14/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.2638 - val_loss: 22.9646\n","Epoch 15/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.2613 - val_loss: 23.5051\n","Epoch 16/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.7334 - val_loss: 22.4273\n","Epoch 17/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.1649 - val_loss: 22.8644\n","Epoch 18/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.2094 - val_loss: 21.5969\n","Epoch 19/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.4018 - val_loss: 22.8872\n","Epoch 20/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.8655 - val_loss: 22.1028\n","Epoch 21/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.1984 - val_loss: 20.7194\n","Epoch 22/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.1469 - val_loss: 22.0714\n","Epoch 23/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.0379 - val_loss: 21.1376\n","Epoch 24/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.5500 - val_loss: 21.3903\n","Epoch 25/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.0944 - val_loss: 20.7658\n","Epoch 26/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.3680 - val_loss: 20.9506\n","Epoch 27/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.5693 - val_loss: 20.7089\n","Epoch 28/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.4399 - val_loss: 20.1188\n","Epoch 29/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.7552 - val_loss: 20.7750\n","Epoch 30/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.4674 - val_loss: 20.7445\n","Epoch 31/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.4856 - val_loss: 19.9750\n","Epoch 32/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.3775 - val_loss: 21.0374\n","Epoch 33/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.2239 - val_loss: 20.0479\n","Epoch 34/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.9306 - val_loss: 20.0796\n","Epoch 35/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.1887 - val_loss: 20.1908\n","Epoch 36/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.4050 - val_loss: 19.9172\n","Epoch 37/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.9785 - val_loss: 19.8662\n","Epoch 38/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.6251 - val_loss: 20.0259\n","Epoch 39/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.0459 - val_loss: 19.5733\n","Epoch 40/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.9733 - val_loss: 20.2848\n","Epoch 41/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.0757 - val_loss: 19.9193\n","Epoch 42/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.8790 - val_loss: 19.3488\n","Epoch 43/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.1092 - val_loss: 19.7041\n","Epoch 44/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.8892 - val_loss: 19.4790\n","Epoch 45/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7303 - val_loss: 19.3590\n","Epoch 46/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.4920 - val_loss: 19.4011\n","Epoch 47/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5235 - val_loss: 19.8057\n","Epoch 48/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7672 - val_loss: 19.2859\n","Epoch 49/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.8929 - val_loss: 19.7006\n","Epoch 50/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7600 - val_loss: 19.1070\n","Epoch 51/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5848 - val_loss: 19.5522\n","Epoch 52/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.3940 - val_loss: 19.6152\n","Epoch 53/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.3921 - val_loss: 19.3759\n","Epoch 54/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.2780 - val_loss: 19.4315\n","Epoch 55/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5548 - val_loss: 19.4484\n","Epoch 56/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7194 - val_loss: 19.2640\n","Epoch 57/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.2987 - val_loss: 19.1161\n","Epoch 58/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5303 - val_loss: 19.2052\n","Epoch 59/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.1586 - val_loss: 19.3899\n","Epoch 60/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.0115 - val_loss: 18.9493\n","Epoch 61/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5958 - val_loss: 19.0548\n","Epoch 62/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.6708 - val_loss: 19.2882\n","Epoch 63/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5343 - val_loss: 19.2790\n","Epoch 64/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.4098 - val_loss: 18.9685\n","Epoch 65/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.4660 - val_loss: 18.9587\n","Epoch 66/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.8590 - val_loss: 18.8146\n","Epoch 67/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.4334 - val_loss: 19.5241\n","Epoch 68/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.4597 - val_loss: 18.9236\n","Epoch 69/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.2514 - val_loss: 18.9300\n","Epoch 70/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.1734 - val_loss: 19.0379\n","Epoch 71/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.7603 - val_loss: 18.9606\n","Epoch 72/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.3050 - val_loss: 19.2216\n","Epoch 73/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.0604 - val_loss: 18.4932\n","Epoch 74/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.8125 - val_loss: 18.8132\n","Epoch 75/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.1691 - val_loss: 19.0338\n","Epoch 76/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.9777 - val_loss: 18.6916\n","Epoch 77/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.1238 - val_loss: 18.5641\n","Epoch 78/100\n","26/26 [==============================] - 0s 3ms/step - loss: 18.9280 - val_loss: 18.6759\n","Epoch 79/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.1576 - val_loss: 18.3868\n","Epoch 80/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.6999 - val_loss: 18.4577\n","Epoch 81/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.5244 - val_loss: 18.4552\n","Epoch 82/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.6805 - val_loss: 18.4673\n","Epoch 83/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.6676 - val_loss: 18.4783\n","Epoch 84/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.7534 - val_loss: 18.5147\n","Epoch 85/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.6936 - val_loss: 18.6720\n","Epoch 86/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.4879 - val_loss: 18.4104\n","Epoch 87/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.1355 - val_loss: 18.4208\n","Epoch 88/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.7880 - val_loss: 18.4631\n","Epoch 89/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.9862 - val_loss: 18.2600\n","Epoch 90/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.4158 - val_loss: 18.6338\n","Epoch 91/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.6413 - val_loss: 18.4917\n","Epoch 92/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.5567 - val_loss: 18.3984\n","Epoch 93/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.7184 - val_loss: 18.7467\n","Epoch 94/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.6648 - val_loss: 18.1791\n","Epoch 95/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.5717 - val_loss: 18.1919\n","Epoch 96/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.1490 - val_loss: 18.1290\n","Epoch 97/100\n","26/26 [==============================] - 0s 3ms/step - loss: 18.2346 - val_loss: 17.9940\n","Epoch 98/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.0238 - val_loss: 18.1219\n","Epoch 99/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.3712 - val_loss: 18.1374\n","Epoch 100/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.2520 - val_loss: 18.1645\n","Addestramento completato in 21.287538 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_148\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_518 (Dense)            (None, 64)                5504      \n","_________________________________________________________________\n","dropout_370 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_519 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 5,569\n","Trainable params: 5,569\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","34/34 [==============================] - 1s 7ms/step - loss: 31.0135 - val_loss: 20.2927\n","Epoch 2/100\n","34/34 [==============================] - 0s 3ms/step - loss: 22.0607 - val_loss: 19.7063\n","Epoch 3/100\n","34/34 [==============================] - 0s 3ms/step - loss: 21.2357 - val_loss: 19.1857\n","Epoch 4/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.8177 - val_loss: 19.0319\n","Epoch 5/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.7580 - val_loss: 18.8710\n","Epoch 6/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.3044 - val_loss: 18.6147\n","Epoch 7/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.0660 - val_loss: 18.6222\n","Epoch 8/100\n","34/34 [==============================] - 0s 2ms/step - loss: 20.1316 - val_loss: 18.4919\n","Epoch 9/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.2172 - val_loss: 18.6497\n","Epoch 10/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.0781 - val_loss: 18.3935\n","Epoch 11/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.8858 - val_loss: 18.2583\n","Epoch 12/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.5230 - val_loss: 18.2979\n","Epoch 13/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.5437 - val_loss: 18.4451\n","Epoch 14/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.4586 - val_loss: 17.9584\n","Epoch 15/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.7382 - val_loss: 17.9367\n","Epoch 16/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.3204 - val_loss: 18.1875\n","Epoch 17/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.7286 - val_loss: 17.9422\n","Epoch 18/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.5123 - val_loss: 17.9112\n","Epoch 19/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.2678 - val_loss: 17.7714\n","Epoch 20/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.0773 - val_loss: 17.8183\n","Epoch 21/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.3267 - val_loss: 17.7982\n","Epoch 22/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1412 - val_loss: 17.6754\n","Epoch 23/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3982 - val_loss: 17.7983\n","Epoch 24/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3900 - val_loss: 17.4902\n","Epoch 25/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.3538 - val_loss: 17.6260\n","Epoch 26/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1173 - val_loss: 17.5089\n","Epoch 27/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9846 - val_loss: 17.3267\n","Epoch 28/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.4307 - val_loss: 17.4260\n","Epoch 29/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.4024 - val_loss: 17.4469\n","Epoch 30/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6981 - val_loss: 17.3369\n","Epoch 31/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.8559 - val_loss: 17.4562\n","Epoch 32/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9363 - val_loss: 17.2199\n","Epoch 33/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1994 - val_loss: 17.2720\n","Epoch 34/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7983 - val_loss: 17.1425\n","Epoch 35/100\n","34/34 [==============================] - 0s 2ms/step - loss: 18.8941 - val_loss: 17.2390\n","Epoch 36/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.5438 - val_loss: 17.4108\n","Epoch 37/100\n","34/34 [==============================] - 0s 2ms/step - loss: 18.3813 - val_loss: 17.1300\n","Epoch 38/100\n","34/34 [==============================] - 0s 2ms/step - loss: 18.4148 - val_loss: 16.9705\n","Epoch 39/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9098 - val_loss: 17.2305\n","Epoch 40/100\n","34/34 [==============================] - 0s 2ms/step - loss: 18.4238 - val_loss: 17.1106\n","Epoch 41/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6961 - val_loss: 17.0992\n","Epoch 42/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7347 - val_loss: 17.1519\n","Epoch 43/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.4363 - val_loss: 17.1261\n","Epoch 44/100\n","34/34 [==============================] - 0s 2ms/step - loss: 18.8157 - val_loss: 17.0968\n","Epoch 45/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6134 - val_loss: 17.1915\n","Epoch 46/100\n","34/34 [==============================] - 0s 2ms/step - loss: 18.5012 - val_loss: 17.0350\n","Epoch 47/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7367 - val_loss: 17.0304\n","Addestramento completato in 5.134310 secondi\n","\n","\n","Model: \"sequential_149\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_520 (Dense)            (None, 1024)              88064     \n","_________________________________________________________________\n","dropout_371 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_521 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_372 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_522 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_373 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_523 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_374 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_524 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 389,375\n","Trainable params: 389,375\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","34/34 [==============================] - 2s 11ms/step - loss: 29.2402 - val_loss: 23.9336\n","Epoch 2/100\n","34/34 [==============================] - 0s 4ms/step - loss: 23.1021 - val_loss: 25.5569\n","Epoch 3/100\n","34/34 [==============================] - 0s 3ms/step - loss: 22.0366 - val_loss: 24.9501\n","Epoch 4/100\n","34/34 [==============================] - 0s 4ms/step - loss: 21.0262 - val_loss: 25.4631\n","Epoch 5/100\n","34/34 [==============================] - 0s 3ms/step - loss: 21.1521 - val_loss: 23.7584\n","Epoch 6/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.4491 - val_loss: 21.8983\n","Epoch 7/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.8073 - val_loss: 22.0565\n","Epoch 8/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.3712 - val_loss: 22.0961\n","Epoch 9/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.9618 - val_loss: 21.6847\n","Epoch 10/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3562 - val_loss: 21.1221\n","Epoch 11/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.8386 - val_loss: 22.1163\n","Epoch 12/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.6363 - val_loss: 20.7394\n","Epoch 13/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3530 - val_loss: 19.9385\n","Epoch 14/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.3831 - val_loss: 20.7429\n","Epoch 15/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.1768 - val_loss: 20.7202\n","Epoch 16/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9392 - val_loss: 19.3917\n","Epoch 17/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.0944 - val_loss: 18.5630\n","Epoch 18/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.8370 - val_loss: 19.2473\n","Epoch 19/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7506 - val_loss: 18.6948\n","Epoch 20/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6993 - val_loss: 18.9881\n","Epoch 21/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9095 - val_loss: 19.1227\n","Epoch 22/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7806 - val_loss: 18.2407\n","Epoch 23/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6304 - val_loss: 18.6975\n","Epoch 24/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.5042 - val_loss: 18.7443\n","Epoch 25/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.3664 - val_loss: 18.2847\n","Epoch 26/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.2426 - val_loss: 17.3647\n","Epoch 27/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.1671 - val_loss: 17.6402\n","Epoch 28/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.5341 - val_loss: 18.1876\n","Epoch 29/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6109 - val_loss: 16.7447\n","Epoch 30/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.1984 - val_loss: 16.9424\n","Epoch 31/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.2530 - val_loss: 17.2712\n","Epoch 32/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.0422 - val_loss: 16.9551\n","Epoch 33/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.7530 - val_loss: 16.9921\n","Epoch 34/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.9213 - val_loss: 16.5779\n","Epoch 35/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.7529 - val_loss: 16.5940\n","Epoch 36/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.8188 - val_loss: 16.0764\n","Epoch 37/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.4385 - val_loss: 16.6348\n","Epoch 38/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.4449 - val_loss: 16.3169\n","Epoch 39/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.6915 - val_loss: 16.2885\n","Epoch 40/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.4949 - val_loss: 16.0904\n","Epoch 41/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.4307 - val_loss: 15.9858\n","Epoch 42/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.4342 - val_loss: 16.0325\n","Epoch 43/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.4780 - val_loss: 15.8666\n","Epoch 44/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.3071 - val_loss: 15.9199\n","Epoch 45/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.3832 - val_loss: 15.9377\n","Epoch 46/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.1642 - val_loss: 15.9089\n","Epoch 47/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.4797 - val_loss: 15.9831\n","Epoch 48/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.0933 - val_loss: 15.8186\n","Epoch 49/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.4435 - val_loss: 15.5394\n","Epoch 50/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.5495 - val_loss: 15.5619\n","Epoch 51/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.5750 - val_loss: 15.5191\n","Epoch 52/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.4016 - val_loss: 16.2239\n","Epoch 53/100\n","34/34 [==============================] - 0s 3ms/step - loss: 16.9851 - val_loss: 15.6953\n","Epoch 54/100\n","34/34 [==============================] - 0s 3ms/step - loss: 16.9989 - val_loss: 15.7534\n","Epoch 55/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.3911 - val_loss: 15.5963\n","Epoch 56/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.3390 - val_loss: 15.7824\n","Epoch 57/100\n","34/34 [==============================] - 0s 3ms/step - loss: 16.9457 - val_loss: 15.8652\n","Epoch 58/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.0355 - val_loss: 15.4073\n","Epoch 59/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.1137 - val_loss: 15.5835\n","Epoch 60/100\n","34/34 [==============================] - 0s 3ms/step - loss: 16.5679 - val_loss: 15.6239\n","Epoch 61/100\n","34/34 [==============================] - 0s 3ms/step - loss: 16.8514 - val_loss: 15.3705\n","Epoch 62/100\n","34/34 [==============================] - 0s 4ms/step - loss: 16.7649 - val_loss: 15.5979\n","Epoch 63/100\n","34/34 [==============================] - 0s 4ms/step - loss: 16.8846 - val_loss: 15.0731\n","Epoch 64/100\n","34/34 [==============================] - 0s 4ms/step - loss: 16.7151 - val_loss: 15.4679\n","Epoch 65/100\n","34/34 [==============================] - 0s 4ms/step - loss: 16.7663 - val_loss: 15.3485\n","Epoch 66/100\n","34/34 [==============================] - 0s 3ms/step - loss: 16.5870 - val_loss: 15.3721\n","Epoch 67/100\n","34/34 [==============================] - 0s 4ms/step - loss: 16.6037 - val_loss: 15.3279\n","Epoch 68/100\n","34/34 [==============================] - 0s 3ms/step - loss: 16.1969 - val_loss: 15.4925\n","Epoch 69/100\n","34/34 [==============================] - 0s 4ms/step - loss: 16.6719 - val_loss: 15.1406\n","Epoch 70/100\n","34/34 [==============================] - 0s 4ms/step - loss: 16.8169 - val_loss: 15.7101\n","Addestramento completato in 10.285685 secondi\n","\n","\n","Model: \"sequential_150\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_525 (Dense)            (None, 64)                3968      \n","_________________________________________________________________\n","dropout_375 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_526 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 4,033\n","Trainable params: 4,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","141/141 [==============================] - 1s 3ms/step - loss: 29.0885 - val_loss: 20.1984\n","Epoch 2/100\n","141/141 [==============================] - 0s 2ms/step - loss: 22.4338 - val_loss: 19.7911\n","Epoch 3/100\n","141/141 [==============================] - 0s 2ms/step - loss: 22.1452 - val_loss: 19.7693\n","Epoch 4/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.9455 - val_loss: 19.6426\n","Epoch 5/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.4043 - val_loss: 19.5415\n","Epoch 6/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.5454 - val_loss: 19.3800\n","Epoch 7/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.4776 - val_loss: 19.3171\n","Epoch 8/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.4016 - val_loss: 19.3437\n","Epoch 9/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.1763 - val_loss: 19.2831\n","Epoch 10/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.8945 - val_loss: 19.1315\n","Epoch 11/100\n","141/141 [==============================] - 0s 2ms/step - loss: 21.0621 - val_loss: 19.2587\n","Epoch 12/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.7455 - val_loss: 19.1528\n","Epoch 13/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.7491 - val_loss: 19.0355\n","Epoch 14/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.8333 - val_loss: 19.0145\n","Epoch 15/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.6617 - val_loss: 18.9867\n","Epoch 16/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.6357 - val_loss: 19.2008\n","Epoch 17/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.3688 - val_loss: 18.9515\n","Epoch 18/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.4785 - val_loss: 19.0263\n","Epoch 19/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.3372 - val_loss: 18.9590\n","Epoch 20/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.3355 - val_loss: 18.9726\n","Epoch 21/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.2022 - val_loss: 18.9448\n","Epoch 22/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.2357 - val_loss: 18.9224\n","Epoch 23/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.1630 - val_loss: 18.9625\n","Epoch 24/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.1091 - val_loss: 18.8795\n","Epoch 25/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.1052 - val_loss: 18.8567\n","Epoch 26/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.1245 - val_loss: 18.9476\n","Epoch 27/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.0328 - val_loss: 18.8996\n","Epoch 28/100\n","141/141 [==============================] - 0s 2ms/step - loss: 20.0574 - val_loss: 18.9596\n","Epoch 29/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.9821 - val_loss: 18.8651\n","Epoch 30/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.9109 - val_loss: 18.8665\n","Epoch 31/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.8116 - val_loss: 18.8409\n","Epoch 32/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.7963 - val_loss: 18.8493\n","Epoch 33/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.9736 - val_loss: 18.8924\n","Epoch 34/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.6954 - val_loss: 18.7978\n","Epoch 35/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.7439 - val_loss: 18.8275\n","Epoch 36/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.7133 - val_loss: 18.7946\n","Epoch 37/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.6159 - val_loss: 18.7529\n","Epoch 38/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.6639 - val_loss: 18.7219\n","Epoch 39/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.6136 - val_loss: 18.7277\n","Epoch 40/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.6679 - val_loss: 18.7229\n","Epoch 41/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4395 - val_loss: 18.6582\n","Epoch 42/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.5341 - val_loss: 18.7128\n","Epoch 43/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4890 - val_loss: 18.6330\n","Epoch 44/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.2914 - val_loss: 18.6142\n","Epoch 45/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4120 - val_loss: 18.5804\n","Epoch 46/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4749 - val_loss: 18.5343\n","Epoch 47/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.3657 - val_loss: 18.4961\n","Epoch 48/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4351 - val_loss: 18.4373\n","Epoch 49/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.3405 - val_loss: 18.4591\n","Epoch 50/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.4379 - val_loss: 18.4120\n","Epoch 51/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.2944 - val_loss: 18.3589\n","Epoch 52/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.1898 - val_loss: 18.4501\n","Epoch 53/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.3342 - val_loss: 18.3784\n","Epoch 54/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9665 - val_loss: 18.2869\n","Epoch 55/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.1629 - val_loss: 18.2721\n","Epoch 56/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.0178 - val_loss: 18.2430\n","Epoch 57/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.1711 - val_loss: 18.2793\n","Epoch 58/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.1872 - val_loss: 18.2641\n","Epoch 59/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.0765 - val_loss: 18.1635\n","Epoch 60/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9739 - val_loss: 18.2017\n","Epoch 61/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9280 - val_loss: 18.0796\n","Epoch 62/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9292 - val_loss: 18.1120\n","Epoch 63/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.0812 - val_loss: 18.0425\n","Epoch 64/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9543 - val_loss: 18.0578\n","Epoch 65/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.1108 - val_loss: 18.1052\n","Epoch 66/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8682 - val_loss: 18.0744\n","Epoch 67/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9417 - val_loss: 17.9353\n","Epoch 68/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8996 - val_loss: 17.9750\n","Epoch 69/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8880 - val_loss: 17.9340\n","Epoch 70/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9748 - val_loss: 17.9575\n","Epoch 71/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.9017 - val_loss: 17.9699\n","Epoch 72/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8230 - val_loss: 17.8262\n","Epoch 73/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7935 - val_loss: 17.9438\n","Epoch 74/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8103 - val_loss: 17.9512\n","Epoch 75/100\n","141/141 [==============================] - 0s 2ms/step - loss: 19.0692 - val_loss: 17.8532\n","Epoch 76/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7428 - val_loss: 17.8763\n","Epoch 77/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8928 - val_loss: 17.7704\n","Epoch 78/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7217 - val_loss: 17.8930\n","Epoch 79/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7681 - val_loss: 17.7902\n","Epoch 80/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7500 - val_loss: 17.8092\n","Epoch 81/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6579 - val_loss: 17.8179\n","Epoch 82/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7561 - val_loss: 17.6791\n","Epoch 83/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6624 - val_loss: 17.7043\n","Epoch 84/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8607 - val_loss: 17.7656\n","Epoch 85/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7291 - val_loss: 17.7516\n","Epoch 86/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5967 - val_loss: 17.6516\n","Epoch 87/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.5744 - val_loss: 17.6793\n","Epoch 88/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8225 - val_loss: 17.7834\n","Epoch 89/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6774 - val_loss: 17.6952\n","Epoch 90/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6353 - val_loss: 17.7270\n","Epoch 91/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7331 - val_loss: 17.7851\n","Epoch 92/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.8119 - val_loss: 17.7263\n","Epoch 93/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6920 - val_loss: 17.7255\n","Epoch 94/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6363 - val_loss: 17.7708\n","Epoch 95/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.6928 - val_loss: 17.7098\n","Epoch 96/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7157 - val_loss: 17.6544\n","Epoch 97/100\n","141/141 [==============================] - 0s 2ms/step - loss: 18.7254 - val_loss: 17.6273\n","Addestramento completato in 31.053389 secondi\n","\n","\n","Model: \"sequential_151\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_527 (Dense)            (None, 1024)              63488     \n","_________________________________________________________________\n","dropout_376 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_528 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_377 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_529 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_378 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_530 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_379 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_531 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 364,799\n","Trainable params: 364,799\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","141/141 [==============================] - 1s 5ms/step - loss: 26.8873 - val_loss: 25.1339\n","Epoch 2/100\n","141/141 [==============================] - 0s 3ms/step - loss: 23.0054 - val_loss: 22.5364\n","Epoch 3/100\n","141/141 [==============================] - 0s 3ms/step - loss: 22.2316 - val_loss: 19.9084\n","Epoch 4/100\n","141/141 [==============================] - 0s 3ms/step - loss: 21.7155 - val_loss: 20.5230\n","Epoch 5/100\n","141/141 [==============================] - 0s 3ms/step - loss: 21.2109 - val_loss: 19.6328\n","Epoch 6/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.9008 - val_loss: 19.7349\n","Epoch 7/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.7619 - val_loss: 19.3310\n","Epoch 8/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.6793 - val_loss: 19.3471\n","Epoch 9/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.5069 - val_loss: 18.9798\n","Epoch 10/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.2943 - val_loss: 18.8234\n","Epoch 11/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.0975 - val_loss: 18.5175\n","Epoch 12/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.1738 - val_loss: 18.5778\n","Epoch 13/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.0821 - val_loss: 18.7263\n","Epoch 14/100\n","141/141 [==============================] - 0s 3ms/step - loss: 20.0482 - val_loss: 18.3373\n","Epoch 15/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.8627 - val_loss: 18.0620\n","Epoch 16/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.8963 - val_loss: 18.1631\n","Epoch 17/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.6569 - val_loss: 18.2915\n","Epoch 18/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.5986 - val_loss: 18.2663\n","Epoch 19/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.7028 - val_loss: 17.9255\n","Epoch 20/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.7577 - val_loss: 18.1230\n","Epoch 21/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.6783 - val_loss: 18.0009\n","Epoch 22/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.4994 - val_loss: 18.2159\n","Epoch 23/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.6707 - val_loss: 17.9070\n","Epoch 24/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.5046 - val_loss: 17.7365\n","Epoch 25/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.5152 - val_loss: 17.7404\n","Epoch 26/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.3884 - val_loss: 17.8144\n","Epoch 27/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.4695 - val_loss: 17.9880\n","Epoch 28/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.3837 - val_loss: 17.6431\n","Epoch 29/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.4057 - val_loss: 17.5984\n","Epoch 30/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.2867 - val_loss: 17.9086\n","Epoch 31/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.2772 - val_loss: 17.7690\n","Epoch 32/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.2784 - val_loss: 17.6677\n","Epoch 33/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.2201 - val_loss: 17.9129\n","Epoch 34/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.5708 - val_loss: 17.7660\n","Epoch 35/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.1981 - val_loss: 17.7132\n","Epoch 36/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.1994 - val_loss: 17.6370\n","Epoch 37/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.0569 - val_loss: 17.5721\n","Epoch 38/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.1078 - val_loss: 17.5588\n","Epoch 39/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.9863 - val_loss: 17.4540\n","Epoch 40/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.8645 - val_loss: 17.5530\n","Epoch 41/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.9440 - val_loss: 17.7719\n","Epoch 42/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.8522 - val_loss: 17.6735\n","Epoch 43/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.0928 - val_loss: 17.3436\n","Epoch 44/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6574 - val_loss: 17.3917\n","Epoch 45/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7851 - val_loss: 17.2774\n","Epoch 46/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7446 - val_loss: 17.6167\n","Epoch 47/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7098 - val_loss: 17.3393\n","Epoch 48/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7720 - val_loss: 17.3299\n","Epoch 49/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.8349 - val_loss: 17.6759\n","Epoch 50/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.8201 - val_loss: 17.4355\n","Epoch 51/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7851 - val_loss: 17.5413\n","Epoch 52/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7082 - val_loss: 17.6914\n","Epoch 53/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.9155 - val_loss: 17.3168\n","Epoch 54/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7033 - val_loss: 17.5064\n","Epoch 55/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.8195 - val_loss: 17.5746\n","Epoch 56/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.9050 - val_loss: 17.2400\n","Epoch 57/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5758 - val_loss: 17.4573\n","Epoch 58/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5692 - val_loss: 17.4196\n","Epoch 59/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7582 - val_loss: 17.3897\n","Epoch 60/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7643 - val_loss: 17.6453\n","Epoch 61/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.8094 - val_loss: 17.4861\n","Epoch 62/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5158 - val_loss: 17.5167\n","Epoch 63/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7880 - val_loss: 17.2849\n","Epoch 64/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5591 - val_loss: 17.7153\n","Epoch 65/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4981 - val_loss: 17.2236\n","Epoch 66/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4757 - val_loss: 17.3293\n","Epoch 67/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7692 - val_loss: 17.3998\n","Epoch 68/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.8635 - val_loss: 17.1857\n","Epoch 69/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5647 - val_loss: 17.2801\n","Epoch 70/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6402 - val_loss: 17.4209\n","Epoch 71/100\n","141/141 [==============================] - 0s 3ms/step - loss: 19.1666 - val_loss: 17.1648\n","Epoch 72/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5272 - val_loss: 17.4742\n","Epoch 73/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.7776 - val_loss: 17.4691\n","Epoch 74/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.6452 - val_loss: 17.2560\n","Epoch 75/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4374 - val_loss: 17.2570\n","Epoch 76/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3934 - val_loss: 17.3092\n","Epoch 77/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5098 - val_loss: 17.3354\n","Epoch 78/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4090 - val_loss: 17.3616\n","Epoch 79/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4977 - val_loss: 17.4174\n","Epoch 80/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3699 - val_loss: 17.3347\n","Epoch 81/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.1810 - val_loss: 17.3646\n","Epoch 82/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4717 - val_loss: 17.2359\n","Epoch 83/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3774 - val_loss: 17.3261\n","Epoch 84/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4177 - val_loss: 17.2303\n","Epoch 85/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3804 - val_loss: 17.1284\n","Epoch 86/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3348 - val_loss: 17.3071\n","Epoch 87/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.2441 - val_loss: 17.2719\n","Epoch 88/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4999 - val_loss: 17.1772\n","Epoch 89/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.1339 - val_loss: 17.3424\n","Epoch 90/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4015 - val_loss: 17.3661\n","Epoch 91/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5122 - val_loss: 17.1477\n","Epoch 92/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5460 - val_loss: 17.3679\n","Epoch 93/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.5802 - val_loss: 17.2489\n","Epoch 94/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4240 - val_loss: 17.2014\n","Epoch 95/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3556 - val_loss: 17.1384\n","Epoch 96/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.3478 - val_loss: 17.3583\n","Epoch 97/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.2449 - val_loss: 17.2259\n","Epoch 98/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4152 - val_loss: 17.2088\n","Epoch 99/100\n","141/141 [==============================] - 0s 3ms/step - loss: 18.4451 - val_loss: 17.2369\n","Addestramento completato in 45.765268 secondi\n","\n","\n","Model: \"sequential_152\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_532 (Dense)            (None, 64)                3968      \n","_________________________________________________________________\n","dropout_380 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_533 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 4,033\n","Trainable params: 4,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","12/12 [==============================] - 1s 21ms/step - loss: 36.0955 - val_loss: 32.6891\n","Epoch 2/100\n","12/12 [==============================] - 0s 4ms/step - loss: 31.4186 - val_loss: 27.9985\n","Epoch 3/100\n","12/12 [==============================] - 0s 5ms/step - loss: 27.1485 - val_loss: 24.2783\n","Epoch 4/100\n","12/12 [==============================] - 0s 4ms/step - loss: 24.2060 - val_loss: 21.9673\n","Epoch 5/100\n","12/12 [==============================] - 0s 4ms/step - loss: 23.8178 - val_loss: 20.9003\n","Epoch 6/100\n","12/12 [==============================] - 0s 4ms/step - loss: 23.1792 - val_loss: 20.5845\n","Epoch 7/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.6920 - val_loss: 20.5044\n","Epoch 8/100\n","12/12 [==============================] - 0s 4ms/step - loss: 23.0006 - val_loss: 20.4548\n","Epoch 9/100\n","12/12 [==============================] - 0s 3ms/step - loss: 22.4091 - val_loss: 20.4043\n","Epoch 10/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.3295 - val_loss: 20.2983\n","Epoch 11/100\n","12/12 [==============================] - 0s 4ms/step - loss: 23.2068 - val_loss: 20.3504\n","Epoch 12/100\n","12/12 [==============================] - 0s 3ms/step - loss: 22.3111 - val_loss: 20.3124\n","Epoch 13/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.2029 - val_loss: 20.1848\n","Epoch 14/100\n","12/12 [==============================] - 0s 3ms/step - loss: 22.5176 - val_loss: 20.1573\n","Epoch 15/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.0128 - val_loss: 20.1806\n","Epoch 16/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.1212 - val_loss: 20.1120\n","Epoch 17/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.5373 - val_loss: 20.0214\n","Epoch 18/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.2123 - val_loss: 20.0827\n","Epoch 19/100\n","12/12 [==============================] - 0s 3ms/step - loss: 21.4751 - val_loss: 19.9406\n","Epoch 20/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.9085 - val_loss: 19.8388\n","Epoch 21/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.3120 - val_loss: 19.8922\n","Epoch 22/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.8916 - val_loss: 19.8223\n","Epoch 23/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.3771 - val_loss: 19.8760\n","Epoch 24/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.9283 - val_loss: 19.7815\n","Epoch 25/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.9222 - val_loss: 19.7618\n","Epoch 26/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.4759 - val_loss: 19.6491\n","Epoch 27/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.6309 - val_loss: 19.6055\n","Epoch 28/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.0407 - val_loss: 19.6501\n","Epoch 29/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.8719 - val_loss: 19.6670\n","Epoch 30/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.5708 - val_loss: 19.5387\n","Epoch 31/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.8166 - val_loss: 19.5145\n","Epoch 32/100\n","12/12 [==============================] - 0s 3ms/step - loss: 21.1957 - val_loss: 19.4732\n","Epoch 33/100\n","12/12 [==============================] - 0s 3ms/step - loss: 22.1779 - val_loss: 19.6588\n","Epoch 34/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.6308 - val_loss: 19.5655\n","Epoch 35/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.0134 - val_loss: 19.5771\n","Epoch 36/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.0746 - val_loss: 19.4919\n","Epoch 37/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.0599 - val_loss: 19.4052\n","Epoch 38/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.3356 - val_loss: 19.4797\n","Epoch 39/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.6625 - val_loss: 19.5765\n","Epoch 40/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.5289 - val_loss: 19.4712\n","Epoch 41/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.6184 - val_loss: 19.4374\n","Epoch 42/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.1506 - val_loss: 19.5710\n","Epoch 43/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.9517 - val_loss: 19.5373\n","Epoch 44/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.8350 - val_loss: 19.4112\n","Epoch 45/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.3664 - val_loss: 19.3665\n","Epoch 46/100\n","12/12 [==============================] - 0s 3ms/step - loss: 21.2370 - val_loss: 19.2559\n","Addestramento completato in 3.063090 secondi\n","\n","\n","Model: \"sequential_153\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_534 (Dense)            (None, 1024)              63488     \n","_________________________________________________________________\n","dropout_381 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_535 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_382 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_536 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_383 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_537 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_384 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_538 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 364,799\n","Trainable params: 364,799\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","12/12 [==============================] - 1s 29ms/step - loss: 33.4947 - val_loss: 20.2780\n","Epoch 2/100\n","12/12 [==============================] - 0s 4ms/step - loss: 25.8202 - val_loss: 27.0708\n","Epoch 3/100\n","12/12 [==============================] - 0s 4ms/step - loss: 24.2904 - val_loss: 22.7365\n","Epoch 4/100\n","12/12 [==============================] - 0s 6ms/step - loss: 23.3620 - val_loss: 23.8676\n","Epoch 5/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.8290 - val_loss: 23.4040\n","Epoch 6/100\n","12/12 [==============================] - 0s 4ms/step - loss: 22.5121 - val_loss: 22.8460\n","Epoch 7/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.5031 - val_loss: 22.7472\n","Epoch 8/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.8010 - val_loss: 23.7483\n","Epoch 9/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.2303 - val_loss: 22.4488\n","Epoch 10/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.9741 - val_loss: 22.6634\n","Epoch 11/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.7575 - val_loss: 24.7189\n","Epoch 12/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.0640 - val_loss: 22.1403\n","Epoch 13/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.2311 - val_loss: 22.9152\n","Epoch 14/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.9922 - val_loss: 23.8590\n","Epoch 15/100\n","12/12 [==============================] - 0s 6ms/step - loss: 21.5089 - val_loss: 22.2993\n","Epoch 16/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.1009 - val_loss: 24.1242\n","Epoch 17/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.7461 - val_loss: 21.3493\n","Epoch 18/100\n","12/12 [==============================] - 0s 6ms/step - loss: 21.5659 - val_loss: 22.3162\n","Epoch 19/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.3347 - val_loss: 22.5938\n","Epoch 20/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.2859 - val_loss: 22.1121\n","Epoch 21/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.9321 - val_loss: 21.2711\n","Epoch 22/100\n","12/12 [==============================] - 0s 6ms/step - loss: 21.0999 - val_loss: 23.1763\n","Epoch 23/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.7264 - val_loss: 22.5415\n","Epoch 24/100\n","12/12 [==============================] - 0s 5ms/step - loss: 21.9028 - val_loss: 21.7741\n","Epoch 25/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.1144 - val_loss: 22.2919\n","Epoch 26/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.5962 - val_loss: 22.8196\n","Epoch 27/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.5138 - val_loss: 22.7255\n","Epoch 28/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.7535 - val_loss: 22.5011\n","Epoch 29/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.0300 - val_loss: 21.8593\n","Epoch 30/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.9557 - val_loss: 21.8859\n","Epoch 31/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.9079 - val_loss: 21.1482\n","Epoch 32/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.6561 - val_loss: 20.9699\n","Epoch 33/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.8437 - val_loss: 21.1543\n","Epoch 34/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.5284 - val_loss: 21.6580\n","Epoch 35/100\n","12/12 [==============================] - 0s 4ms/step - loss: 21.2247 - val_loss: 20.6871\n","Epoch 36/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.3920 - val_loss: 21.9041\n","Epoch 37/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.2710 - val_loss: 21.7355\n","Epoch 38/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.9372 - val_loss: 20.9631\n","Epoch 39/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.0191 - val_loss: 20.8168\n","Epoch 40/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.2033 - val_loss: 21.5873\n","Epoch 41/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.6926 - val_loss: 20.7662\n","Epoch 42/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.9371 - val_loss: 20.9142\n","Epoch 43/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.3533 - val_loss: 20.5629\n","Epoch 44/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.3265 - val_loss: 21.1697\n","Epoch 45/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.9968 - val_loss: 20.0827\n","Epoch 46/100\n","12/12 [==============================] - 0s 6ms/step - loss: 20.1134 - val_loss: 21.3839\n","Epoch 47/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.3650 - val_loss: 20.2364\n","Epoch 48/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.4258 - val_loss: 20.4911\n","Epoch 49/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.1619 - val_loss: 19.9225\n","Epoch 50/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.4739 - val_loss: 19.9786\n","Epoch 51/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.1633 - val_loss: 20.2329\n","Epoch 52/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.3901 - val_loss: 20.8333\n","Epoch 53/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.8768 - val_loss: 19.5791\n","Epoch 54/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.8949 - val_loss: 20.3913\n","Epoch 55/100\n","12/12 [==============================] - 0s 4ms/step - loss: 20.0705 - val_loss: 19.8055\n","Epoch 56/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.9512 - val_loss: 19.7805\n","Epoch 57/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.9789 - val_loss: 20.5667\n","Epoch 58/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.6514 - val_loss: 19.7823\n","Epoch 59/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.0713 - val_loss: 19.6003\n","Epoch 60/100\n","12/12 [==============================] - 0s 6ms/step - loss: 20.1673 - val_loss: 19.9253\n","Epoch 61/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.0884 - val_loss: 20.3326\n","Epoch 62/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.4432 - val_loss: 19.1389\n","Epoch 63/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.0683 - val_loss: 20.7569\n","Epoch 64/100\n","12/12 [==============================] - 0s 5ms/step - loss: 20.2511 - val_loss: 19.6599\n","Epoch 65/100\n","12/12 [==============================] - 0s 7ms/step - loss: 19.7404 - val_loss: 19.2116\n","Epoch 66/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.9873 - val_loss: 19.7886\n","Epoch 67/100\n","12/12 [==============================] - 0s 5ms/step - loss: 19.6416 - val_loss: 19.4376\n","Epoch 68/100\n","12/12 [==============================] - 0s 4ms/step - loss: 19.4775 - val_loss: 19.3954\n","Addestramento completato in 5.562590 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_154\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_539 (Dense)            (None, 64)                3968      \n","_________________________________________________________________\n","dropout_385 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_540 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 4,033\n","Trainable params: 4,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","15/15 [==============================] - 1s 15ms/step - loss: 42.3259 - val_loss: 31.8868\n","Epoch 2/100\n","15/15 [==============================] - 0s 3ms/step - loss: 32.6417 - val_loss: 26.0455\n","Epoch 3/100\n","15/15 [==============================] - 0s 3ms/step - loss: 27.2320 - val_loss: 22.9380\n","Epoch 4/100\n","15/15 [==============================] - 0s 3ms/step - loss: 25.7262 - val_loss: 21.5840\n","Epoch 5/100\n","15/15 [==============================] - 0s 3ms/step - loss: 25.2948 - val_loss: 21.2155\n","Epoch 6/100\n","15/15 [==============================] - 0s 3ms/step - loss: 24.7527 - val_loss: 21.0241\n","Epoch 7/100\n","15/15 [==============================] - 0s 3ms/step - loss: 24.9012 - val_loss: 20.9410\n","Epoch 8/100\n","15/15 [==============================] - 0s 3ms/step - loss: 24.9395 - val_loss: 20.8937\n","Epoch 9/100\n","15/15 [==============================] - 0s 5ms/step - loss: 24.6624 - val_loss: 20.7643\n","Epoch 10/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.7619 - val_loss: 20.6406\n","Epoch 11/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.9292 - val_loss: 20.5029\n","Epoch 12/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.4764 - val_loss: 20.4346\n","Epoch 13/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.7668 - val_loss: 20.3685\n","Epoch 14/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.0656 - val_loss: 20.2866\n","Epoch 15/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.4794 - val_loss: 20.2973\n","Epoch 16/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.6512 - val_loss: 20.2190\n","Epoch 17/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.9489 - val_loss: 20.1458\n","Epoch 18/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.8669 - val_loss: 20.1181\n","Epoch 19/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.4571 - val_loss: 20.1298\n","Epoch 20/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.1106 - val_loss: 20.0788\n","Epoch 21/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.7386 - val_loss: 20.0600\n","Epoch 22/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.3102 - val_loss: 20.0218\n","Epoch 23/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.5881 - val_loss: 19.9745\n","Epoch 24/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.6839 - val_loss: 19.9262\n","Epoch 25/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.1215 - val_loss: 19.9293\n","Epoch 26/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.6599 - val_loss: 19.9037\n","Epoch 27/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.4494 - val_loss: 19.9082\n","Epoch 28/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.2762 - val_loss: 19.8470\n","Epoch 29/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.2833 - val_loss: 19.8214\n","Epoch 30/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.0399 - val_loss: 19.8249\n","Epoch 31/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.7589 - val_loss: 19.8318\n","Epoch 32/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.8012 - val_loss: 19.8074\n","Epoch 33/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.3617 - val_loss: 19.7896\n","Epoch 34/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.3438 - val_loss: 19.7973\n","Epoch 35/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.7950 - val_loss: 19.8046\n","Epoch 36/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.3855 - val_loss: 19.7791\n","Epoch 37/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.5867 - val_loss: 19.7741\n","Epoch 38/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.2125 - val_loss: 19.7598\n","Epoch 39/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.8940 - val_loss: 19.7928\n","Epoch 40/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.6858 - val_loss: 19.7762\n","Epoch 41/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1705 - val_loss: 19.7172\n","Epoch 42/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.5646 - val_loss: 19.7027\n","Epoch 43/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.8422 - val_loss: 19.7068\n","Epoch 44/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.6069 - val_loss: 19.7035\n","Epoch 45/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.3494 - val_loss: 19.5613\n","Epoch 46/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.5187 - val_loss: 19.6693\n","Epoch 47/100\n","15/15 [==============================] - 0s 5ms/step - loss: 22.3100 - val_loss: 19.6207\n","Epoch 48/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.3499 - val_loss: 19.6410\n","Epoch 49/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.3578 - val_loss: 19.6230\n","Epoch 50/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.8089 - val_loss: 19.6316\n","Epoch 51/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.2054 - val_loss: 19.5654\n","Epoch 52/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.2738 - val_loss: 19.5711\n","Epoch 53/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.6906 - val_loss: 19.6855\n","Epoch 54/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.0847 - val_loss: 19.6615\n","Epoch 55/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1019 - val_loss: 19.6317\n","Epoch 56/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.7418 - val_loss: 19.6110\n","Epoch 57/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7262 - val_loss: 19.5975\n","Epoch 58/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.5437 - val_loss: 19.6070\n","Epoch 59/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1383 - val_loss: 19.6171\n","Epoch 60/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.4236 - val_loss: 19.5954\n","Epoch 61/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1089 - val_loss: 19.5645\n","Epoch 62/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.3773 - val_loss: 19.5526\n","Epoch 63/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.7347 - val_loss: 19.5970\n","Epoch 64/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.3033 - val_loss: 19.6220\n","Epoch 65/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.6332 - val_loss: 19.5698\n","Epoch 66/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.0516 - val_loss: 19.5399\n","Epoch 67/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.9658 - val_loss: 19.5168\n","Epoch 68/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.2513 - val_loss: 19.6400\n","Epoch 69/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1794 - val_loss: 19.5600\n","Epoch 70/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.2859 - val_loss: 19.6094\n","Epoch 71/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.5450 - val_loss: 19.5995\n","Epoch 72/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.0417 - val_loss: 19.6274\n","Epoch 73/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8279 - val_loss: 19.5046\n","Epoch 74/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.0957 - val_loss: 19.4698\n","Epoch 75/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.8164 - val_loss: 19.5133\n","Epoch 76/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.3260 - val_loss: 19.4889\n","Addestramento completato in 4.778552 secondi\n","\n","\n","Model: \"sequential_155\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_541 (Dense)            (None, 1024)              63488     \n","_________________________________________________________________\n","dropout_386 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_542 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_387 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_543 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_388 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_544 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_389 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_545 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 364,799\n","Trainable params: 364,799\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","15/15 [==============================] - 1s 26ms/step - loss: 36.0382 - val_loss: 22.7805\n","Epoch 2/100\n","15/15 [==============================] - 0s 6ms/step - loss: 27.0270 - val_loss: 24.0620\n","Epoch 3/100\n","15/15 [==============================] - 0s 4ms/step - loss: 24.2921 - val_loss: 22.9620\n","Epoch 4/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.7395 - val_loss: 24.0043\n","Epoch 5/100\n","15/15 [==============================] - 0s 5ms/step - loss: 23.4150 - val_loss: 23.1779\n","Epoch 6/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.0345 - val_loss: 23.7436\n","Epoch 7/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.6024 - val_loss: 23.5076\n","Epoch 8/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.5515 - val_loss: 22.1438\n","Epoch 9/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.5036 - val_loss: 21.6998\n","Epoch 10/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.8843 - val_loss: 22.6453\n","Epoch 11/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.1168 - val_loss: 22.8296\n","Epoch 12/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.5648 - val_loss: 23.4962\n","Epoch 13/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.1535 - val_loss: 22.9129\n","Epoch 14/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.3993 - val_loss: 21.8837\n","Epoch 15/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.2943 - val_loss: 21.5821\n","Epoch 16/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.8356 - val_loss: 21.8970\n","Epoch 17/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.0912 - val_loss: 21.9569\n","Epoch 18/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.1495 - val_loss: 21.5563\n","Epoch 19/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.8248 - val_loss: 22.5396\n","Epoch 20/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.0094 - val_loss: 20.9557\n","Epoch 21/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.1076 - val_loss: 20.7507\n","Epoch 22/100\n","15/15 [==============================] - 0s 5ms/step - loss: 22.0650 - val_loss: 21.6617\n","Epoch 23/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.6186 - val_loss: 22.3587\n","Epoch 24/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.9234 - val_loss: 21.7492\n","Epoch 25/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.1770 - val_loss: 21.0038\n","Epoch 26/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.4448 - val_loss: 21.0435\n","Epoch 27/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7249 - val_loss: 21.2346\n","Epoch 28/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.6576 - val_loss: 19.8711\n","Epoch 29/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.2019 - val_loss: 20.3006\n","Epoch 30/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.8411 - val_loss: 20.5404\n","Epoch 31/100\n","15/15 [==============================] - 0s 5ms/step - loss: 21.4277 - val_loss: 20.5274\n","Epoch 32/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1598 - val_loss: 20.2461\n","Epoch 33/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.4409 - val_loss: 20.9686\n","Epoch 34/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0729 - val_loss: 20.2793\n","Epoch 35/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7580 - val_loss: 20.2759\n","Epoch 36/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7685 - val_loss: 20.5180\n","Epoch 37/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.3120 - val_loss: 19.8616\n","Epoch 38/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7017 - val_loss: 19.9973\n","Epoch 39/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.5055 - val_loss: 20.6864\n","Epoch 40/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.4896 - val_loss: 20.1958\n","Epoch 41/100\n","15/15 [==============================] - 0s 6ms/step - loss: 20.8799 - val_loss: 19.4152\n","Epoch 42/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0093 - val_loss: 19.5332\n","Epoch 43/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8634 - val_loss: 20.2225\n","Epoch 44/100\n","15/15 [==============================] - 0s 5ms/step - loss: 20.6360 - val_loss: 20.0483\n","Epoch 45/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.6644 - val_loss: 19.8090\n","Epoch 46/100\n","15/15 [==============================] - 0s 5ms/step - loss: 20.3015 - val_loss: 19.8950\n","Epoch 47/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8942 - val_loss: 19.5163\n","Epoch 48/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.6725 - val_loss: 19.4231\n","Epoch 49/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8712 - val_loss: 19.5722\n","Epoch 50/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4739 - val_loss: 19.2315\n","Epoch 51/100\n","15/15 [==============================] - 0s 5ms/step - loss: 20.6376 - val_loss: 19.3761\n","Epoch 52/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8317 - val_loss: 19.0431\n","Epoch 53/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8070 - val_loss: 19.4189\n","Epoch 54/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.9220 - val_loss: 19.4734\n","Epoch 55/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4759 - val_loss: 19.3591\n","Epoch 56/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.3794 - val_loss: 19.3045\n","Epoch 57/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.5172 - val_loss: 19.3023\n","Epoch 58/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.2117 - val_loss: 19.1019\n","Epoch 59/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7007 - val_loss: 19.0374\n","Epoch 60/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.5318 - val_loss: 19.0309\n","Epoch 61/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.2015 - val_loss: 19.1164\n","Epoch 62/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4145 - val_loss: 19.2325\n","Epoch 63/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.5871 - val_loss: 19.0276\n","Epoch 64/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4969 - val_loss: 19.1521\n","Epoch 65/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.1251 - val_loss: 19.3808\n","Epoch 66/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.8130 - val_loss: 19.0892\n","Epoch 67/100\n","15/15 [==============================] - 0s 5ms/step - loss: 20.4190 - val_loss: 18.9010\n","Epoch 68/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.1647 - val_loss: 18.9440\n","Addestramento completato in 5.881091 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_156\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_546 (Dense)            (None, 64)                3968      \n","_________________________________________________________________\n","dropout_390 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_547 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 4,033\n","Trainable params: 4,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","15/15 [==============================] - 1s 15ms/step - loss: 43.7531 - val_loss: 35.2234\n","Epoch 2/100\n","15/15 [==============================] - 0s 3ms/step - loss: 33.7156 - val_loss: 27.2057\n","Epoch 3/100\n","15/15 [==============================] - 0s 3ms/step - loss: 27.8649 - val_loss: 23.5250\n","Epoch 4/100\n","15/15 [==============================] - 0s 3ms/step - loss: 25.7763 - val_loss: 22.5882\n","Epoch 5/100\n","15/15 [==============================] - 0s 4ms/step - loss: 25.2591 - val_loss: 22.1313\n","Epoch 6/100\n","15/15 [==============================] - 0s 3ms/step - loss: 24.2163 - val_loss: 21.7114\n","Epoch 7/100\n","15/15 [==============================] - 0s 3ms/step - loss: 24.0913 - val_loss: 21.3590\n","Epoch 8/100\n","15/15 [==============================] - 0s 3ms/step - loss: 23.2811 - val_loss: 20.9577\n","Epoch 9/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.6604 - val_loss: 20.5902\n","Epoch 10/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.6875 - val_loss: 20.4111\n","Epoch 11/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.5517 - val_loss: 20.1783\n","Epoch 12/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.4205 - val_loss: 20.0797\n","Epoch 13/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1720 - val_loss: 19.9518\n","Epoch 14/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1087 - val_loss: 19.9208\n","Epoch 15/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1620 - val_loss: 19.7946\n","Epoch 16/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7388 - val_loss: 19.7198\n","Epoch 17/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.0059 - val_loss: 19.6710\n","Epoch 18/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8004 - val_loss: 19.6106\n","Epoch 19/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.5437 - val_loss: 19.5905\n","Epoch 20/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.2483 - val_loss: 19.5657\n","Epoch 21/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.4637 - val_loss: 19.4317\n","Epoch 22/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.5713 - val_loss: 19.4249\n","Epoch 23/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.3679 - val_loss: 19.4366\n","Epoch 24/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8628 - val_loss: 19.3755\n","Epoch 25/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.1499 - val_loss: 19.3633\n","Epoch 26/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.8433 - val_loss: 19.3641\n","Epoch 27/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.0592 - val_loss: 19.2558\n","Epoch 28/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.7706 - val_loss: 19.2436\n","Epoch 29/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.4607 - val_loss: 19.3016\n","Epoch 30/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3152 - val_loss: 19.2332\n","Epoch 31/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3603 - val_loss: 19.1327\n","Epoch 32/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3025 - val_loss: 19.2109\n","Epoch 33/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.1876 - val_loss: 19.1471\n","Epoch 34/100\n","15/15 [==============================] - 0s 3ms/step - loss: 22.1057 - val_loss: 19.1395\n","Epoch 35/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3723 - val_loss: 19.1529\n","Epoch 36/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.2515 - val_loss: 19.0445\n","Epoch 37/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.2137 - val_loss: 19.0803\n","Epoch 38/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.6571 - val_loss: 19.1359\n","Epoch 39/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.6726 - val_loss: 18.9221\n","Epoch 40/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.9066 - val_loss: 18.9619\n","Epoch 41/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.8794 - val_loss: 19.0493\n","Epoch 42/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.9574 - val_loss: 18.8998\n","Epoch 43/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.7981 - val_loss: 18.8793\n","Epoch 44/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.1861 - val_loss: 18.9379\n","Epoch 45/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.9633 - val_loss: 18.9025\n","Epoch 46/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.3632 - val_loss: 18.9057\n","Epoch 47/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.9011 - val_loss: 18.8473\n","Epoch 48/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.6099 - val_loss: 18.8406\n","Epoch 49/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.6332 - val_loss: 18.8220\n","Epoch 50/100\n","15/15 [==============================] - 0s 3ms/step - loss: 21.9519 - val_loss: 18.7938\n","Epoch 51/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.8551 - val_loss: 18.6973\n","Epoch 52/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.8830 - val_loss: 18.7335\n","Epoch 53/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.7287 - val_loss: 18.7959\n","Epoch 54/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.8363 - val_loss: 18.7558\n","Epoch 55/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.4400 - val_loss: 18.6743\n","Epoch 56/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.8308 - val_loss: 18.7064\n","Epoch 57/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.6137 - val_loss: 18.7465\n","Epoch 58/100\n","15/15 [==============================] - 0s 3ms/step - loss: 20.7238 - val_loss: 18.7142\n","Addestramento completato in 3.711793 secondi\n","\n","\n","Model: \"sequential_157\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_548 (Dense)            (None, 1024)              63488     \n","_________________________________________________________________\n","dropout_391 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_549 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_392 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_550 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_393 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_551 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_394 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_552 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 364,799\n","Trainable params: 364,799\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","15/15 [==============================] - 1s 23ms/step - loss: 37.4335 - val_loss: 25.6125\n","Epoch 2/100\n","15/15 [==============================] - 0s 4ms/step - loss: 26.8939 - val_loss: 23.4033\n","Epoch 3/100\n","15/15 [==============================] - 0s 4ms/step - loss: 25.7630 - val_loss: 24.5161\n","Epoch 4/100\n","15/15 [==============================] - 0s 4ms/step - loss: 24.3074 - val_loss: 23.5301\n","Epoch 5/100\n","15/15 [==============================] - 0s 4ms/step - loss: 24.1202 - val_loss: 22.9129\n","Epoch 6/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.0198 - val_loss: 23.1869\n","Epoch 7/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.2882 - val_loss: 23.3738\n","Epoch 8/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.2227 - val_loss: 23.4111\n","Epoch 9/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.5777 - val_loss: 22.6869\n","Epoch 10/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.9551 - val_loss: 23.0320\n","Epoch 11/100\n","15/15 [==============================] - 0s 4ms/step - loss: 23.0946 - val_loss: 23.0000\n","Epoch 12/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.2726 - val_loss: 22.8136\n","Epoch 13/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.2076 - val_loss: 22.3925\n","Epoch 14/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.5155 - val_loss: 22.4567\n","Epoch 15/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.9684 - val_loss: 22.1286\n","Epoch 16/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.8555 - val_loss: 21.7357\n","Epoch 17/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.3606 - val_loss: 22.0890\n","Epoch 18/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.3565 - val_loss: 21.3244\n","Epoch 19/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.9269 - val_loss: 21.8235\n","Epoch 20/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0897 - val_loss: 20.6779\n","Epoch 21/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.3006 - val_loss: 21.3557\n","Epoch 22/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.6157 - val_loss: 20.0942\n","Epoch 23/100\n","15/15 [==============================] - 0s 4ms/step - loss: 22.0419 - val_loss: 20.3648\n","Epoch 24/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.7340 - val_loss: 20.2513\n","Epoch 25/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.9027 - val_loss: 19.8957\n","Epoch 26/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.7050 - val_loss: 19.9370\n","Epoch 27/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1308 - val_loss: 20.5644\n","Epoch 28/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.5575 - val_loss: 20.0580\n","Epoch 29/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.4169 - val_loss: 20.0157\n","Epoch 30/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1676 - val_loss: 19.5800\n","Epoch 31/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.4949 - val_loss: 19.6264\n","Epoch 32/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1705 - val_loss: 19.1535\n","Epoch 33/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.1357 - val_loss: 18.9972\n","Epoch 34/100\n","15/15 [==============================] - 0s 6ms/step - loss: 20.7159 - val_loss: 19.2480\n","Epoch 35/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.6961 - val_loss: 18.7551\n","Epoch 36/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7881 - val_loss: 18.5997\n","Epoch 37/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.9296 - val_loss: 19.3398\n","Epoch 38/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.7226 - val_loss: 18.8915\n","Epoch 39/100\n","15/15 [==============================] - 0s 27ms/step - loss: 20.5986 - val_loss: 18.7434\n","Epoch 40/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8995 - val_loss: 18.6771\n","Epoch 41/100\n","15/15 [==============================] - 0s 4ms/step - loss: 21.0983 - val_loss: 18.6879\n","Epoch 42/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.0843 - val_loss: 18.1796\n","Epoch 43/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.0383 - val_loss: 18.5867\n","Epoch 44/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.2181 - val_loss: 18.5944\n","Epoch 45/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4646 - val_loss: 18.1607\n","Epoch 46/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.5426 - val_loss: 18.6335\n","Epoch 47/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.0770 - val_loss: 18.2693\n","Epoch 48/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.6366 - val_loss: 18.8244\n","Epoch 49/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.1945 - val_loss: 18.6878\n","Epoch 50/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.5934 - val_loss: 18.8499\n","Epoch 51/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.3307 - val_loss: 18.8265\n","Epoch 52/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.9349 - val_loss: 18.4564\n","Epoch 53/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.0086 - val_loss: 18.2952\n","Epoch 54/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.7786 - val_loss: 17.7943\n","Epoch 55/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.9031 - val_loss: 18.0226\n","Epoch 56/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8320 - val_loss: 18.4227\n","Epoch 57/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.9747 - val_loss: 17.7537\n","Epoch 58/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.7297 - val_loss: 17.8570\n","Epoch 59/100\n","15/15 [==============================] - 0s 5ms/step - loss: 20.1343 - val_loss: 17.7234\n","Epoch 60/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.7594 - val_loss: 17.8671\n","Epoch 61/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.9875 - val_loss: 17.8564\n","Epoch 62/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.4108 - val_loss: 17.7411\n","Epoch 63/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3453 - val_loss: 17.6563\n","Epoch 64/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.9070 - val_loss: 17.5853\n","Epoch 65/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8609 - val_loss: 17.4251\n","Epoch 66/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0036 - val_loss: 17.6321\n","Epoch 67/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8387 - val_loss: 17.6000\n","Epoch 68/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3691 - val_loss: 18.0224\n","Epoch 69/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.7474 - val_loss: 17.6442\n","Epoch 70/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.6618 - val_loss: 17.5154\n","Epoch 71/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.5814 - val_loss: 17.4737\n","Epoch 72/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2493 - val_loss: 17.4934\n","Epoch 73/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4744 - val_loss: 17.9107\n","Epoch 74/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.6848 - val_loss: 17.6379\n","Epoch 75/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2141 - val_loss: 17.5954\n","Epoch 76/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.5925 - val_loss: 17.2097\n","Epoch 77/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8948 - val_loss: 17.1749\n","Epoch 78/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.5267 - val_loss: 17.2157\n","Epoch 79/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4158 - val_loss: 17.3522\n","Epoch 80/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.0662 - val_loss: 17.2317\n","Epoch 81/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4626 - val_loss: 17.4096\n","Epoch 82/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.5450 - val_loss: 17.4374\n","Epoch 83/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4461 - val_loss: 17.3832\n","Epoch 84/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.4933 - val_loss: 17.3926\n","Epoch 85/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.8756 - val_loss: 18.1721\n","Epoch 86/100\n","15/15 [==============================] - 0s 4ms/step - loss: 20.0302 - val_loss: 17.5146\n","Epoch 87/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.5219 - val_loss: 17.1430\n","Epoch 88/100\n","15/15 [==============================] - 0s 5ms/step - loss: 19.5930 - val_loss: 17.2977\n","Epoch 89/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.2872 - val_loss: 17.4207\n","Epoch 90/100\n","15/15 [==============================] - 0s 4ms/step - loss: 19.3659 - val_loss: 17.2825\n","Addestramento completato in 7.558345 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_158\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_553 (Dense)            (None, 64)                3968      \n","_________________________________________________________________\n","dropout_395 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_554 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 4,033\n","Trainable params: 4,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","19/19 [==============================] - 1s 11ms/step - loss: 38.1733 - val_loss: 27.5594\n","Epoch 2/100\n","19/19 [==============================] - 0s 3ms/step - loss: 27.8896 - val_loss: 22.9141\n","Epoch 3/100\n","19/19 [==============================] - 0s 3ms/step - loss: 24.7822 - val_loss: 22.0556\n","Epoch 4/100\n","19/19 [==============================] - 0s 3ms/step - loss: 24.9205 - val_loss: 21.7874\n","Epoch 5/100\n","19/19 [==============================] - 0s 3ms/step - loss: 24.3970 - val_loss: 21.4993\n","Epoch 6/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.5364 - val_loss: 21.2411\n","Epoch 7/100\n","19/19 [==============================] - 0s 3ms/step - loss: 24.3325 - val_loss: 21.0806\n","Epoch 8/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.8254 - val_loss: 20.8173\n","Epoch 9/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.5676 - val_loss: 20.8313\n","Epoch 10/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.3438 - val_loss: 20.6563\n","Epoch 11/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.9868 - val_loss: 20.6309\n","Epoch 12/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.7272 - val_loss: 20.5061\n","Epoch 13/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.8196 - val_loss: 20.4698\n","Epoch 14/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.2728 - val_loss: 20.3983\n","Epoch 15/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.5013 - val_loss: 20.2845\n","Epoch 16/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.1506 - val_loss: 20.2734\n","Epoch 17/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.7901 - val_loss: 20.3625\n","Epoch 18/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.0072 - val_loss: 20.2014\n","Epoch 19/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.2324 - val_loss: 20.1407\n","Epoch 20/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.2000 - val_loss: 20.2179\n","Epoch 21/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.6027 - val_loss: 20.2152\n","Epoch 22/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.3055 - val_loss: 20.1395\n","Epoch 23/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.5184 - val_loss: 20.0929\n","Epoch 24/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.0846 - val_loss: 20.0937\n","Addestramento completato in 2.103608 secondi\n","\n","\n","Model: \"sequential_159\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_555 (Dense)            (None, 1024)              63488     \n","_________________________________________________________________\n","dropout_396 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_556 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_397 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_557 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_398 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_558 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_399 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_559 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 364,799\n","Trainable params: 364,799\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","19/19 [==============================] - 1s 19ms/step - loss: 36.4711 - val_loss: 26.0973\n","Epoch 2/100\n","19/19 [==============================] - 0s 4ms/step - loss: 26.4479 - val_loss: 24.0326\n","Epoch 3/100\n","19/19 [==============================] - 0s 4ms/step - loss: 24.8002 - val_loss: 23.1008\n","Epoch 4/100\n","19/19 [==============================] - 0s 3ms/step - loss: 23.7562 - val_loss: 23.4971\n","Epoch 5/100\n","19/19 [==============================] - 0s 4ms/step - loss: 23.6141 - val_loss: 23.1161\n","Epoch 6/100\n","19/19 [==============================] - 0s 4ms/step - loss: 23.7494 - val_loss: 23.3706\n","Epoch 7/100\n","19/19 [==============================] - 0s 4ms/step - loss: 23.0061 - val_loss: 22.5845\n","Epoch 8/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.7617 - val_loss: 23.6556\n","Epoch 9/100\n","19/19 [==============================] - 0s 4ms/step - loss: 23.1076 - val_loss: 23.3604\n","Epoch 10/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.6673 - val_loss: 22.9410\n","Epoch 11/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.6057 - val_loss: 22.6466\n","Epoch 12/100\n","19/19 [==============================] - 0s 4ms/step - loss: 23.0059 - val_loss: 22.5793\n","Epoch 13/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.7151 - val_loss: 21.2400\n","Epoch 14/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.3230 - val_loss: 21.1437\n","Epoch 15/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.5413 - val_loss: 21.2356\n","Epoch 16/100\n","19/19 [==============================] - 0s 3ms/step - loss: 22.1859 - val_loss: 22.5890\n","Epoch 17/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.9098 - val_loss: 22.8094\n","Epoch 18/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.0792 - val_loss: 22.1659\n","Epoch 19/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.7099 - val_loss: 20.8708\n","Epoch 20/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.9859 - val_loss: 20.3101\n","Epoch 21/100\n","19/19 [==============================] - 0s 4ms/step - loss: 22.1269 - val_loss: 20.8656\n","Epoch 22/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.6351 - val_loss: 20.9438\n","Epoch 23/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.4014 - val_loss: 21.2002\n","Epoch 24/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.0793 - val_loss: 20.6427\n","Epoch 25/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.6500 - val_loss: 21.7610\n","Epoch 26/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.5258 - val_loss: 20.3129\n","Epoch 27/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.0451 - val_loss: 20.9006\n","Epoch 28/100\n","19/19 [==============================] - 0s 3ms/step - loss: 21.7428 - val_loss: 21.0728\n","Epoch 29/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.1788 - val_loss: 19.7892\n","Epoch 30/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.3197 - val_loss: 20.5038\n","Epoch 31/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.8532 - val_loss: 19.9782\n","Epoch 32/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.0664 - val_loss: 20.0672\n","Epoch 33/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.5764 - val_loss: 20.3546\n","Epoch 34/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.6947 - val_loss: 20.4614\n","Epoch 35/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.9343 - val_loss: 19.7900\n","Epoch 36/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.2155 - val_loss: 19.8517\n","Epoch 37/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.9587 - val_loss: 20.2551\n","Epoch 38/100\n","19/19 [==============================] - 0s 4ms/step - loss: 21.1661 - val_loss: 19.8731\n","Epoch 39/100\n","19/19 [==============================] - 0s 5ms/step - loss: 20.7645 - val_loss: 19.6765\n","Epoch 40/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.9696 - val_loss: 19.5673\n","Epoch 41/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.9280 - val_loss: 19.6667\n","Epoch 42/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.9982 - val_loss: 19.6295\n","Epoch 43/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.4501 - val_loss: 19.9086\n","Epoch 44/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.8205 - val_loss: 19.5952\n","Epoch 45/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.0080 - val_loss: 19.5376\n","Epoch 46/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.4923 - val_loss: 19.6791\n","Epoch 47/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.7613 - val_loss: 19.6308\n","Epoch 48/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.4952 - val_loss: 19.6798\n","Epoch 49/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.9131 - val_loss: 19.7447\n","Epoch 50/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.5951 - val_loss: 19.5275\n","Epoch 51/100\n","19/19 [==============================] - 0s 3ms/step - loss: 20.8132 - val_loss: 19.3150\n","Epoch 52/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.7281 - val_loss: 19.2627\n","Epoch 53/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.1704 - val_loss: 19.5454\n","Epoch 54/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.4001 - val_loss: 19.4647\n","Epoch 55/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.4370 - val_loss: 19.4045\n","Epoch 56/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.8981 - val_loss: 19.6778\n","Epoch 57/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.9416 - val_loss: 19.5161\n","Epoch 58/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.1960 - val_loss: 19.3727\n","Epoch 59/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.5733 - val_loss: 19.3975\n","Epoch 60/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.7773 - val_loss: 19.1716\n","Epoch 61/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.3227 - val_loss: 19.6469\n","Epoch 62/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.3296 - val_loss: 19.4368\n","Epoch 63/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.1953 - val_loss: 19.4680\n","Epoch 64/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.1646 - val_loss: 19.3681\n","Epoch 65/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.2917 - val_loss: 19.2220\n","Epoch 66/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.3181 - val_loss: 19.2319\n","Epoch 67/100\n","19/19 [==============================] - 0s 4ms/step - loss: 20.1830 - val_loss: 19.1828\n","Epoch 68/100\n","19/19 [==============================] - 0s 5ms/step - loss: 20.5055 - val_loss: 19.6024\n","Addestramento completato in 6.711309 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_160\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_560 (Dense)            (None, 64)                3968      \n","_________________________________________________________________\n","dropout_400 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_561 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 4,033\n","Trainable params: 4,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","26/26 [==============================] - 1s 9ms/step - loss: 35.8169 - val_loss: 24.6548\n","Epoch 2/100\n","26/26 [==============================] - 0s 3ms/step - loss: 24.9912 - val_loss: 21.8097\n","Epoch 3/100\n","26/26 [==============================] - 0s 3ms/step - loss: 24.1158 - val_loss: 21.5493\n","Epoch 4/100\n","26/26 [==============================] - 0s 3ms/step - loss: 23.5969 - val_loss: 21.0831\n","Epoch 5/100\n","26/26 [==============================] - 0s 3ms/step - loss: 23.3887 - val_loss: 20.8204\n","Epoch 6/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.9348 - val_loss: 20.7479\n","Epoch 7/100\n","26/26 [==============================] - 0s 2ms/step - loss: 22.7167 - val_loss: 20.6577\n","Epoch 8/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.4733 - val_loss: 20.4454\n","Epoch 9/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.4953 - val_loss: 20.4678\n","Epoch 10/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.4343 - val_loss: 20.3713\n","Epoch 11/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.9444 - val_loss: 20.3461\n","Epoch 12/100\n","26/26 [==============================] - 0s 2ms/step - loss: 22.0919 - val_loss: 20.3341\n","Epoch 13/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.5060 - val_loss: 20.3428\n","Epoch 14/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.9041 - val_loss: 20.3233\n","Epoch 15/100\n","26/26 [==============================] - 0s 2ms/step - loss: 22.1066 - val_loss: 20.3707\n","Epoch 16/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.7764 - val_loss: 20.0413\n","Epoch 17/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.0656 - val_loss: 20.2995\n","Epoch 18/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.2064 - val_loss: 20.0539\n","Epoch 19/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.9067 - val_loss: 20.0346\n","Epoch 20/100\n","26/26 [==============================] - 0s 2ms/step - loss: 22.0637 - val_loss: 20.1099\n","Epoch 21/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.0566 - val_loss: 19.9510\n","Epoch 22/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.5047 - val_loss: 19.9347\n","Epoch 23/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.5893 - val_loss: 19.8629\n","Epoch 24/100\n","26/26 [==============================] - 0s 2ms/step - loss: 22.0461 - val_loss: 20.0696\n","Epoch 25/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.6778 - val_loss: 19.8522\n","Epoch 26/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.2121 - val_loss: 19.8962\n","Epoch 27/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.9330 - val_loss: 20.0978\n","Epoch 28/100\n","26/26 [==============================] - 0s 3ms/step - loss: 22.3767 - val_loss: 19.8878\n","Epoch 29/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.6466 - val_loss: 19.7159\n","Epoch 30/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.6329 - val_loss: 20.0155\n","Epoch 31/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.6800 - val_loss: 19.8813\n","Epoch 32/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.6765 - val_loss: 19.8414\n","Epoch 33/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.2843 - val_loss: 19.6308\n","Epoch 34/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.5412 - val_loss: 19.8221\n","Epoch 35/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.2339 - val_loss: 19.7849\n","Epoch 36/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.2972 - val_loss: 19.6710\n","Epoch 37/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.7560 - val_loss: 19.7493\n","Epoch 38/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.3366 - val_loss: 19.6429\n","Epoch 39/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.2793 - val_loss: 19.6691\n","Epoch 40/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.1574 - val_loss: 19.9304\n","Epoch 41/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.5327 - val_loss: 19.6985\n","Epoch 42/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.4950 - val_loss: 19.6037\n","Epoch 43/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.0329 - val_loss: 19.7373\n","Epoch 44/100\n","26/26 [==============================] - 0s 3ms/step - loss: 21.4190 - val_loss: 19.6104\n","Epoch 45/100\n","26/26 [==============================] - 0s 2ms/step - loss: 21.5014 - val_loss: 19.5818\n","Addestramento completato in 4.001028 secondi\n","\n","\n","Model: \"sequential_161\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_562 (Dense)            (None, 1024)              63488     \n","_________________________________________________________________\n","dropout_401 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_563 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_402 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_564 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_403 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_565 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_404 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_566 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 364,799\n","Trainable params: 364,799\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","26/26 [==============================] - 1s 15ms/step - loss: 31.4915 - val_loss: 27.6694\n","Epoch 2/100\n","26/26 [==============================] - 0s 4ms/step - loss: 25.4997 - val_loss: 25.9551\n","Epoch 3/100\n","26/26 [==============================] - 0s 4ms/step - loss: 23.8347 - val_loss: 24.5792\n","Epoch 4/100\n","26/26 [==============================] - 0s 3ms/step - loss: 23.9723 - val_loss: 26.3638\n","Epoch 5/100\n","26/26 [==============================] - 0s 4ms/step - loss: 23.0711 - val_loss: 25.3329\n","Epoch 6/100\n","26/26 [==============================] - 0s 4ms/step - loss: 23.2881 - val_loss: 24.0748\n","Epoch 7/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.9304 - val_loss: 23.9946\n","Epoch 8/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.3222 - val_loss: 23.3069\n","Epoch 9/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.4327 - val_loss: 23.7678\n","Epoch 10/100\n","26/26 [==============================] - 0s 4ms/step - loss: 22.5479 - val_loss: 22.0338\n","Epoch 11/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.8818 - val_loss: 22.8784\n","Epoch 12/100\n","26/26 [==============================] - 0s 5ms/step - loss: 22.1753 - val_loss: 23.5574\n","Epoch 13/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.8603 - val_loss: 20.8771\n","Epoch 14/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.9257 - val_loss: 22.6135\n","Epoch 15/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.6552 - val_loss: 22.4385\n","Epoch 16/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.9306 - val_loss: 22.1759\n","Epoch 17/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.8227 - val_loss: 21.6720\n","Epoch 18/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.5464 - val_loss: 22.2351\n","Epoch 19/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.3444 - val_loss: 21.0464\n","Epoch 20/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.4460 - val_loss: 20.6320\n","Epoch 21/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.9226 - val_loss: 21.1496\n","Epoch 22/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.1537 - val_loss: 21.1699\n","Epoch 23/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.3006 - val_loss: 20.3348\n","Epoch 24/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.8058 - val_loss: 20.7265\n","Epoch 25/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.2532 - val_loss: 20.1431\n","Epoch 26/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.1714 - val_loss: 20.9202\n","Epoch 27/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.0377 - val_loss: 20.5833\n","Epoch 28/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.9811 - val_loss: 20.8288\n","Epoch 29/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.6012 - val_loss: 19.6396\n","Epoch 30/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.2181 - val_loss: 20.1800\n","Epoch 31/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.5519 - val_loss: 20.2270\n","Epoch 32/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.6186 - val_loss: 20.0511\n","Epoch 33/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.8601 - val_loss: 20.2342\n","Epoch 34/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.8179 - val_loss: 20.1656\n","Epoch 35/100\n","26/26 [==============================] - 0s 4ms/step - loss: 21.0799 - val_loss: 19.7241\n","Epoch 36/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.9578 - val_loss: 19.7804\n","Epoch 37/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.7621 - val_loss: 19.6947\n","Epoch 38/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.5431 - val_loss: 19.7928\n","Epoch 39/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.8103 - val_loss: 19.4937\n","Epoch 40/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.3802 - val_loss: 19.4487\n","Epoch 41/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.5002 - val_loss: 19.8348\n","Epoch 42/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.2974 - val_loss: 19.2933\n","Epoch 43/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.3444 - val_loss: 19.3064\n","Epoch 44/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.3972 - val_loss: 19.3040\n","Epoch 45/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.1292 - val_loss: 19.1919\n","Epoch 46/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.4083 - val_loss: 19.4641\n","Epoch 47/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.1936 - val_loss: 19.5774\n","Epoch 48/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.4312 - val_loss: 19.1062\n","Epoch 49/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.6252 - val_loss: 19.3004\n","Epoch 50/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.0976 - val_loss: 18.8004\n","Epoch 51/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.2315 - val_loss: 19.4391\n","Epoch 52/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.5060 - val_loss: 19.1585\n","Epoch 53/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.4157 - val_loss: 18.9509\n","Epoch 54/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.6737 - val_loss: 18.9806\n","Epoch 55/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.3850 - val_loss: 19.0971\n","Epoch 56/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.3362 - val_loss: 19.7223\n","Epoch 57/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.2091 - val_loss: 18.7568\n","Epoch 58/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.1020 - val_loss: 18.7184\n","Epoch 59/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.1059 - val_loss: 18.8329\n","Epoch 60/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.8417 - val_loss: 19.1286\n","Epoch 61/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.1157 - val_loss: 18.5748\n","Epoch 62/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.9027 - val_loss: 18.8484\n","Epoch 63/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.8085 - val_loss: 18.7559\n","Epoch 64/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.6440 - val_loss: 19.0154\n","Epoch 65/100\n","26/26 [==============================] - 0s 3ms/step - loss: 20.1578 - val_loss: 18.7323\n","Epoch 66/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.9266 - val_loss: 18.3279\n","Epoch 67/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7986 - val_loss: 18.7828\n","Epoch 68/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.6848 - val_loss: 18.4250\n","Epoch 69/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7777 - val_loss: 18.3385\n","Epoch 70/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5135 - val_loss: 18.6801\n","Epoch 71/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.5519 - val_loss: 18.1211\n","Epoch 72/100\n","26/26 [==============================] - 0s 3ms/step - loss: 19.6511 - val_loss: 18.1681\n","Epoch 73/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.8144 - val_loss: 18.2576\n","Epoch 74/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5741 - val_loss: 18.8976\n","Epoch 75/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.8322 - val_loss: 18.2477\n","Epoch 76/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5855 - val_loss: 18.7452\n","Epoch 77/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.3544 - val_loss: 18.2269\n","Epoch 78/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.4382 - val_loss: 18.5405\n","Epoch 79/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.4459 - val_loss: 18.5262\n","Epoch 80/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7183 - val_loss: 19.4730\n","Epoch 81/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.2678 - val_loss: 18.7677\n","Epoch 82/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.0191 - val_loss: 19.0845\n","Epoch 83/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5322 - val_loss: 18.1707\n","Epoch 84/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5792 - val_loss: 18.0854\n","Epoch 85/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.3018 - val_loss: 18.8997\n","Epoch 86/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5762 - val_loss: 17.7393\n","Epoch 87/100\n","26/26 [==============================] - 0s 4ms/step - loss: 18.8721 - val_loss: 18.2669\n","Epoch 88/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7268 - val_loss: 18.4597\n","Epoch 89/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5454 - val_loss: 18.2174\n","Epoch 90/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5288 - val_loss: 19.2223\n","Epoch 91/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.6674 - val_loss: 18.6693\n","Epoch 92/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.6961 - val_loss: 18.4296\n","Epoch 93/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.1162 - val_loss: 18.2831\n","Epoch 94/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.5050 - val_loss: 17.8353\n","Epoch 95/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.7369 - val_loss: 19.2746\n","Epoch 96/100\n","26/26 [==============================] - 0s 4ms/step - loss: 19.3533 - val_loss: 18.1218\n","Epoch 97/100\n","26/26 [==============================] - 0s 4ms/step - loss: 20.1267 - val_loss: 18.1367\n","Addestramento completato in 11.353225 secondi\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Model: \"sequential_162\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_567 (Dense)            (None, 64)                3968      \n","_________________________________________________________________\n","dropout_405 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_568 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 4,033\n","Trainable params: 4,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","34/34 [==============================] - 1s 7ms/step - loss: 30.7963 - val_loss: 20.6373\n","Epoch 2/100\n","34/34 [==============================] - 0s 3ms/step - loss: 21.9074 - val_loss: 19.5344\n","Epoch 3/100\n","34/34 [==============================] - 0s 3ms/step - loss: 21.9658 - val_loss: 19.3274\n","Epoch 4/100\n","34/34 [==============================] - 0s 3ms/step - loss: 21.2215 - val_loss: 19.1126\n","Epoch 5/100\n","34/34 [==============================] - 0s 2ms/step - loss: 20.4036 - val_loss: 18.9269\n","Epoch 6/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.5467 - val_loss: 18.8950\n","Epoch 7/100\n","34/34 [==============================] - 0s 2ms/step - loss: 20.5760 - val_loss: 18.8398\n","Epoch 8/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.8460 - val_loss: 18.7407\n","Epoch 9/100\n","34/34 [==============================] - 0s 2ms/step - loss: 20.4945 - val_loss: 18.6928\n","Epoch 10/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.2417 - val_loss: 18.7819\n","Epoch 11/100\n","34/34 [==============================] - 0s 2ms/step - loss: 20.3090 - val_loss: 18.7461\n","Epoch 12/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.2261 - val_loss: 18.6451\n","Epoch 13/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.1915 - val_loss: 18.5964\n","Epoch 14/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.2104 - val_loss: 18.4333\n","Epoch 15/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.2179 - val_loss: 18.4160\n","Epoch 16/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.9698 - val_loss: 18.6433\n","Epoch 17/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.0556 - val_loss: 18.4435\n","Epoch 18/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.9351 - val_loss: 18.2889\n","Epoch 19/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.0497 - val_loss: 18.3904\n","Epoch 20/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.8414 - val_loss: 18.4514\n","Epoch 21/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.9496 - val_loss: 18.3242\n","Epoch 22/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.4435 - val_loss: 18.4350\n","Epoch 23/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.9431 - val_loss: 18.3225\n","Epoch 24/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.7674 - val_loss: 18.1750\n","Epoch 25/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.5715 - val_loss: 18.3530\n","Epoch 26/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.7813 - val_loss: 18.2083\n","Epoch 27/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.4733 - val_loss: 18.2675\n","Epoch 28/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3878 - val_loss: 18.1826\n","Epoch 29/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.5610 - val_loss: 18.2379\n","Epoch 30/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.4382 - val_loss: 18.1137\n","Epoch 31/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3359 - val_loss: 18.0230\n","Epoch 32/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.4274 - val_loss: 18.0553\n","Epoch 33/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3472 - val_loss: 18.1232\n","Epoch 34/100\n","34/34 [==============================] - 0s 2ms/step - loss: 19.5841 - val_loss: 18.1883\n","Epoch 35/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.5369 - val_loss: 18.0273\n","Epoch 36/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.2852 - val_loss: 18.1684\n","Epoch 37/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3325 - val_loss: 18.2378\n","Epoch 38/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3094 - val_loss: 18.2514\n","Epoch 39/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3092 - val_loss: 18.1332\n","Epoch 40/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.0332 - val_loss: 18.0739\n","Epoch 41/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.7826 - val_loss: 18.1915\n","Epoch 42/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.2028 - val_loss: 17.9547\n","Epoch 43/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3455 - val_loss: 18.0691\n","Epoch 44/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3202 - val_loss: 18.1988\n","Epoch 45/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3104 - val_loss: 18.0413\n","Epoch 46/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.2500 - val_loss: 17.9670\n","Epoch 47/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.3620 - val_loss: 17.8708\n","Epoch 48/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.2330 - val_loss: 18.1494\n","Epoch 49/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1220 - val_loss: 18.0841\n","Epoch 50/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1256 - val_loss: 17.9917\n","Epoch 51/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.0581 - val_loss: 17.9705\n","Epoch 52/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9225 - val_loss: 17.9455\n","Epoch 53/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.2080 - val_loss: 17.9906\n","Epoch 54/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1847 - val_loss: 17.9594\n","Epoch 55/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9890 - val_loss: 17.9644\n","Epoch 56/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6681 - val_loss: 17.9271\n","Epoch 57/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9009 - val_loss: 17.8734\n","Epoch 58/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1353 - val_loss: 18.0803\n","Epoch 59/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.0840 - val_loss: 17.9584\n","Epoch 60/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.0141 - val_loss: 17.8271\n","Epoch 61/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9705 - val_loss: 17.9554\n","Epoch 62/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1222 - val_loss: 17.8280\n","Epoch 63/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.0523 - val_loss: 17.8996\n","Epoch 64/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.2624 - val_loss: 17.8462\n","Epoch 65/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9670 - val_loss: 17.9515\n","Epoch 66/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.1532 - val_loss: 18.2325\n","Epoch 67/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9032 - val_loss: 17.9305\n","Epoch 68/100\n","34/34 [==============================] - 0s 2ms/step - loss: 18.4364 - val_loss: 17.9940\n","Epoch 69/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9809 - val_loss: 17.9079\n","Epoch 70/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.5537 - val_loss: 17.9677\n","Epoch 71/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7293 - val_loss: 17.9588\n","Epoch 72/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.2301 - val_loss: 17.9188\n","Epoch 73/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.8868 - val_loss: 17.8184\n","Epoch 74/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7715 - val_loss: 17.8439\n","Epoch 75/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.0479 - val_loss: 17.9265\n","Epoch 76/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7318 - val_loss: 17.9677\n","Epoch 77/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.8798 - val_loss: 18.0280\n","Epoch 78/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.0915 - val_loss: 17.8086\n","Epoch 79/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7661 - val_loss: 17.8984\n","Epoch 80/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6295 - val_loss: 17.8444\n","Addestramento completato in 8.562863 secondi\n","\n","\n","Model: \"sequential_163\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_569 (Dense)            (None, 1024)              63488     \n","_________________________________________________________________\n","dropout_406 (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","dense_570 (Dense)            (None, 254)               260350    \n","_________________________________________________________________\n","dropout_407 (Dropout)        (None, 254)               0         \n","_________________________________________________________________\n","dense_571 (Dense)            (None, 128)               32640     \n","_________________________________________________________________\n","dropout_408 (Dropout)        (None, 128)               0         \n","_________________________________________________________________\n","dense_572 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dropout_409 (Dropout)        (None, 64)                0         \n","_________________________________________________________________\n","dense_573 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 364,799\n","Trainable params: 364,799\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","34/34 [==============================] - 1s 12ms/step - loss: 29.8451 - val_loss: 23.2080\n","Epoch 2/100\n","34/34 [==============================] - 0s 4ms/step - loss: 22.5379 - val_loss: 23.5779\n","Epoch 3/100\n","34/34 [==============================] - 0s 4ms/step - loss: 21.7557 - val_loss: 23.0682\n","Epoch 4/100\n","34/34 [==============================] - 0s 4ms/step - loss: 21.3059 - val_loss: 21.9401\n","Epoch 5/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.9388 - val_loss: 23.4031\n","Epoch 6/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.6818 - val_loss: 21.7246\n","Epoch 7/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.7673 - val_loss: 23.2464\n","Epoch 8/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.4547 - val_loss: 20.3389\n","Epoch 9/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.4954 - val_loss: 20.9470\n","Epoch 10/100\n","34/34 [==============================] - 0s 3ms/step - loss: 20.5094 - val_loss: 20.2025\n","Epoch 11/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.8270 - val_loss: 19.9925\n","Epoch 12/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.6631 - val_loss: 20.1128\n","Epoch 13/100\n","34/34 [==============================] - 0s 4ms/step - loss: 20.0146 - val_loss: 20.6236\n","Epoch 14/100\n","34/34 [==============================] - 0s 4ms/step - loss: 20.0569 - val_loss: 20.3993\n","Epoch 15/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.6393 - val_loss: 20.4429\n","Epoch 16/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.6505 - val_loss: 19.5835\n","Epoch 17/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.5056 - val_loss: 19.8230\n","Epoch 18/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.4880 - val_loss: 19.4367\n","Epoch 19/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.5085 - val_loss: 19.0388\n","Epoch 20/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.1125 - val_loss: 19.2145\n","Epoch 21/100\n","34/34 [==============================] - 0s 3ms/step - loss: 19.4030 - val_loss: 19.3984\n","Epoch 22/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.9845 - val_loss: 18.8834\n","Epoch 23/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.1466 - val_loss: 18.6553\n","Epoch 24/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.1465 - val_loss: 18.5607\n","Epoch 25/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.9689 - val_loss: 18.1374\n","Epoch 26/100\n","34/34 [==============================] - 0s 4ms/step - loss: 19.1052 - val_loss: 17.9185\n","Epoch 27/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.9070 - val_loss: 17.7681\n","Epoch 28/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.7759 - val_loss: 18.0759\n","Epoch 29/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.6603 - val_loss: 17.7703\n","Epoch 30/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.5532 - val_loss: 17.5785\n","Epoch 31/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.6303 - val_loss: 17.6234\n","Epoch 32/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.5918 - val_loss: 17.6902\n","Epoch 33/100\n","34/34 [==============================] - 0s 5ms/step - loss: 18.6337 - val_loss: 17.7226\n","Epoch 34/100\n","34/34 [==============================] - 0s 5ms/step - loss: 18.6862 - val_loss: 18.0533\n","Epoch 35/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.3442 - val_loss: 17.5238\n","Epoch 36/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.8038 - val_loss: 17.4346\n","Epoch 37/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.5013 - val_loss: 17.0240\n","Epoch 38/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.2054 - val_loss: 16.9233\n","Epoch 39/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.0649 - val_loss: 17.0703\n","Epoch 40/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.4589 - val_loss: 17.5314\n","Epoch 41/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.8253 - val_loss: 17.3392\n","Epoch 42/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.3260 - val_loss: 16.6839\n","Epoch 43/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.3233 - val_loss: 16.9921\n","Epoch 44/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.8102 - val_loss: 17.3111\n","Epoch 45/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.1059 - val_loss: 16.8625\n","Epoch 46/100\n","34/34 [==============================] - 0s 3ms/step - loss: 18.3859 - val_loss: 16.8855\n","Epoch 47/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.0235 - val_loss: 17.2723\n","Epoch 48/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.9922 - val_loss: 17.4113\n","Epoch 49/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.8943 - val_loss: 17.0022\n","Epoch 50/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.8628 - val_loss: 17.2372\n","Epoch 51/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.8993 - val_loss: 17.1619\n","Epoch 52/100\n","34/34 [==============================] - 0s 4ms/step - loss: 18.4898 - val_loss: 16.9281\n","Epoch 53/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.9275 - val_loss: 17.2078\n","Epoch 54/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.9738 - val_loss: 16.6534\n","Epoch 55/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.7730 - val_loss: 17.0684\n","Epoch 56/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.5912 - val_loss: 16.5256\n","Epoch 57/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.8667 - val_loss: 16.4260\n","Epoch 58/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.9025 - val_loss: 16.3509\n","Epoch 59/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.5694 - val_loss: 16.6091\n","Epoch 60/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.4136 - val_loss: 17.1485\n","Epoch 61/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.6817 - val_loss: 16.6117\n","Epoch 62/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.4912 - val_loss: 16.4801\n","Epoch 63/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.8885 - val_loss: 16.3995\n","Epoch 64/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.9457 - val_loss: 16.7728\n","Epoch 65/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.3187 - val_loss: 16.4958\n","Epoch 66/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.8346 - val_loss: 16.6828\n","Epoch 67/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.8015 - val_loss: 16.5682\n","Epoch 68/100\n","34/34 [==============================] - 0s 4ms/step - loss: 17.8066 - val_loss: 16.6211\n","Epoch 69/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.5360 - val_loss: 16.5543\n","Epoch 70/100\n","34/34 [==============================] - 0s 3ms/step - loss: 17.5973 - val_loss: 16.6278\n","Addestramento completato in 10.372428 secondi\n"]}],"source":["category = 'deep learning'\n","problem = 'regression'\n","#oversample_algorithm = SMOTE\n","class_balancing = 'year-weighted undersample'\n","\n","earlyStopping = EarlyStopping(monitor='loss', min_delta=0.001, patience=10, restore_best_weights=True)\n","\n","result_df_array = []\n","\n","x = 'all' # --\u003e parametro da variare per considerare le new_features calcolate sui diversi intorni di anni --\u003e [0,1,2,3,'all']\n","\n","# # # FEATURES SELECT # # #\n","\n","std_features_list = ['valence','acousticness','danceability','duration_ms','energy','instrumentalness','liveness','loudness','speechiness','tempo','explicit','key_0','key_1','key_2','key_3','key_4','key_5','key_6','key_7','key_8','key_9','key_10','key_11','mode'] \n","\n","if(x == 'all'):\n","  new_features = ['valence_new','acousticness_new','danceability_new','duration_ms_new','energy_new','instrumentalness_new','liveness_new','loudness_new','speechiness_new','tempo_new','explicit_new','key_new','mode_new']\n","  new_features_list = []\n","\n","  for i in range(4):\n","    for feat in new_features:\n","      new_features_list.append(feat + '_' + str(i))\n","else:\n","  new_features_list = ['valence_new_'+str(x),'acousticness_new_'+str(x),'danceability_new_'+str(x),'duration_ms_new_'+str(x),'energy_new_'+str(x),'instrumentalness_new_'+str(x),'liveness_new_'+str(x),'loudness_new_'+str(x),'speechiness_new_'+str(x),'tempo_new_'+str(x),'explicit_new_'+str(x),'key_new_'+str(x),'mode_new_'+str(x)]\n","\n","extra_features = ['month','year','cos(month)','sin(month)','season_1','season_2','season_3','season_4', 'past_pop_n_hit', 'past_pop_n_weeks']\n","targets_list = ['hit', 'weeks_enc']\n","\n","features_select = {'standard features': std_features_list+extra_features, 'standard + new features': std_features_list+new_features_list+extra_features, 'new features': new_features_list+extra_features}\n","\n","for current_features in ['standard + new features', 'new features']: # features_select.keys()\n","\n","    if(current_features != 'standard features'):\n","      new_features_params = x\n","    else:\n","      new_features_params = None\n","\n","    # # # YEAR RANGE SELECT # # #\n","\n","    year_range_select = [(1960,2020), (1960,1969), (1970,1979), (1980,1989), (1990,1999), (2000,2009), (2010,2020)]\n","\n","    for year_range in year_range_select:\n","\n","      # bilancio dataset\n","      df = undersample(df, 'hit', 'year_YYYY')\n","\n","      year_start = year_range[0]\n","      year_end = year_range[1]\n","\n","      # seleziono sotto_df\n","      mask_1 = df.year_YYYY \u003e= year_start\n","      mask_2 = df.year_YYYY \u003c= year_end\n","      sub_df = df[mask_1]\n","      sub_df = sub_df[mask_2]\n","\n","      # regolo dimensione test set in base a numero di anni considerato\n","      if((year_end - year_start) \u003e 10):\n","          test_size = 0.2\n","          val_size = int(0.05 * sub_df.shape[0])\n","      else:\n","          test_size = 0.3\n","          val_size = int(0.08 * sub_df.shape[0])\n","      \n","      # creo validation set\n","      sub_df = shuffle(sub_df)\n","      val_set = sub_df.iloc[:val_size].copy()\n","      sub_df = sub_df.iloc[val_size:].copy()\n","\n","      # seleziono features correnti\n","      features = features_select[current_features]\n","\n","      # creo array numpy\n","      X_val = val_set[features].drop(['month'], axis=1).values\n","      Y_val = val_set['weeks_enc'].values\n","      \n","      X = sub_df[features].drop(['month'], axis=1).values\n","      Y = sub_df['weeks_enc'].values\n","      \n","      # creo set addestramento e test\n","      X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)\n","\n","\n","      # ------------------------------------------- #\n","\n","      # MODELLI\n","\n","      # --- model_0 --- #\n","\n","      model_0 = Sequential()\n","      # hidden layer\n","      model_0.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n","      model_0.add(Dropout(0.75))\n","      # output layer\n","      model_0.add(Dense(1,activation='linear'))\n","\n","      # --- model_1 --- #\n","\n","      model_1 = Sequential()\n","      # hidden layer\n","      model_1.add(Dense(1024, input_dim=X_train.shape[1], activation='relu'))\n","      model_1.add(Dropout(0.75))\n","      # hidden layer\n","      model_1.add(Dense(254, activation='relu'))\n","      model_1.add(Dropout(0.65))\n","      # hidden layer\n","      model_1.add(Dense(128, activation='relu'))\n","      model_1.add(Dropout(0.65))\n","      # hidden layer\n","      model_1.add(Dense(64, activation='relu'))\n","      model_1.add(Dropout(0.6))\n","      # output layer\n","      model_1.add(Dense(1,activation='linear'))\n","\n","      models = [model_0, model_1]\n","\n","      for i, model in enumerate(models):\n","\n","        adam = optimizers.Adam()  # learning_rate=learning_rates[i]\n","\n","        model.compile(optimizer=adam, loss='mean_squared_error')\n","        print('\\n')\n","        model.summary()\n","\n","        time_0 = time()\n","        model.fit(X_train,Y_train, epochs=100, validation_data=(X_val, Y_val), batch_size=254, callbacks=[earlyStopping])\n","        print_exec_time(time_0)\n","\n","        # METRICHE\n","\n","        # test set\n","        Y_pred = model.predict(X_test) # effettuo predizioni\n","\n","        # calcolo metriche\n","        MSE = mean_squared_error(Y_test, Y_pred)\n","        r2 = r2_score(Y_test, Y_pred)\n","\n","        # train set\n","        Y_pred_train = model.predict(X_train) # effettuo predizioni\n","\n","        # calcolo metriche\n","        MSE_train = mean_squared_error(Y_train, Y_pred_train)\n","        r2_train = r2_score(Y_train, Y_pred_train)\n","\n","        # imposto a None le metriche della classificazione\n","        accuracy = None\n","        loss = None\n","        precision = [None, None]\n","        recall = [None, None]\n","        fscore = [None, None]\n","        conf_matrix = None\n","        accuracy_train = None\n","        loss_train = None\n","        precision_train = [None, None]\n","        recall_train = [None, None]\n","        fscore_train = [None, None]\n","        conf_matrix_train = None\n","\n","        if(i == 1):\n","          parameters = '1 hidden layer (64)'\n","        else:\n","          parameters = '4 hidden layers (1024, 254, 128, 64)'\n","\n","        tot_time = time() - time_0\n","\n","        result_df = pd.DataFrame(\n","                [['MLP',\n","                parameters,\n","                class_balancing,\n","                problem,\n","                accuracy,\n","                loss,\n","                conf_matrix,\n","                precision[0],\n","                precision[1],\n","                recall[0],\n","                recall[1],\n","                fscore[0],\n","                fscore[1],\n","                accuracy_train,\n","                loss_train,\n","                conf_matrix_train,\n","                precision_train[0],\n","                precision_train[1],\n","                recall_train[0],\n","                recall_train[1],\n","                fscore_train[0],\n","                fscore_train[1],\n","                MSE,\n","                r2,\n","                MSE_train,\n","                r2_train,\n","                tot_time]],\n","          columns=['algorithm',\n","                  'parameters',\n","                  'class_balancing',\n","                  'problem',\n","                  'test_accuracy',\n","                  'test_log_loss',\n","                  'test_confusion_matrix',\n","                  'test_precision_0',\n","                  'test_precision_1', \n","                  'test_recall_0',\n","                  'test_recall_1',\n","                  'test_fscore_0',\n","                  'test_fscore_1',\n","                  'train_accuracy',\n","                  'train_log_loss',\n","                  'train_confusion_matrix',\n","                  'train_precision_0',\n","                  'train_precision_1',\n","                  'train_recall_0',\n","                  'train_recall_1',\n","                  'train_fscore_0',\n","                  'train_fscore_1',\n","                  'test_MSE',\n","                  'test_r2',\n","                  'train_MSE',\n","                  'train_r2',\n","                  'tot_time'])\n","        \n","\n","        # inserisco campi mancanti\n","\n","        # year_range\n","        year_range_array = [year_range for i in range(result_df.shape[0])]\n","        result_df.insert(0, 'year_range', year_range_array)\n","\n","        # features\n","        features_array = [current_features for i in range(result_df.shape[0])]\n","        result_df.insert(0, 'features', features_array)\n","\n","        # new_features_params\n","        new_features_params_array = [new_features_params for i in range(result_df.shape[0])]\n","        result_df.insert(0, 'new_features_params', new_features_params_array)\n","\n","        # category\n","        category_array = ['deep learning' for i in range(result_df.shape[0])]\n","        result_df.insert(0, 'category', category_array)\n","        \n","        result_df_array.append(result_df)\n","\n","df_tot = pd.concat(result_df_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"r7gKfm1MnDo-"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ecategory\u003c/th\u003e\n","      \u003cth\u003enew_features_params\u003c/th\u003e\n","      \u003cth\u003efeatures\u003c/th\u003e\n","      \u003cth\u003eyear_range\u003c/th\u003e\n","      \u003cth\u003ealgorithm\u003c/th\u003e\n","      \u003cth\u003eparameters\u003c/th\u003e\n","      \u003cth\u003eclass_balancing\u003c/th\u003e\n","      \u003cth\u003eproblem\u003c/th\u003e\n","      \u003cth\u003etest_accuracy\u003c/th\u003e\n","      \u003cth\u003etest_log_loss\u003c/th\u003e\n","      \u003cth\u003etest_confusion_matrix\u003c/th\u003e\n","      \u003cth\u003etest_precision_0\u003c/th\u003e\n","      \u003cth\u003etest_precision_1\u003c/th\u003e\n","      \u003cth\u003etest_recall_0\u003c/th\u003e\n","      \u003cth\u003etest_recall_1\u003c/th\u003e\n","      \u003cth\u003etest_fscore_0\u003c/th\u003e\n","      \u003cth\u003etest_fscore_1\u003c/th\u003e\n","      \u003cth\u003etrain_accuracy\u003c/th\u003e\n","      \u003cth\u003etrain_log_loss\u003c/th\u003e\n","      \u003cth\u003etrain_confusion_matrix\u003c/th\u003e\n","      \u003cth\u003etrain_precision_0\u003c/th\u003e\n","      \u003cth\u003etrain_precision_1\u003c/th\u003e\n","      \u003cth\u003etrain_recall_0\u003c/th\u003e\n","      \u003cth\u003etrain_recall_1\u003c/th\u003e\n","      \u003cth\u003etrain_fscore_0\u003c/th\u003e\n","      \u003cth\u003etrain_fscore_1\u003c/th\u003e\n","      \u003cth\u003etest_MSE\u003c/th\u003e\n","      \u003cth\u003etest_r2\u003c/th\u003e\n","      \u003cth\u003etrain_MSE\u003c/th\u003e\n","      \u003cth\u003etrain_r2\u003c/th\u003e\n","      \u003cth\u003etot_time\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1980, 1989)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e18.111715\u003c/td\u003e\n","      \u003ctd\u003e0.172229\u003c/td\u003e\n","      \u003ctd\u003e17.876539\u003c/td\u003e\n","      \u003ctd\u003e0.186282\u003c/td\u003e\n","      \u003ctd\u003e11.464724\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1960, 2020)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e17.413362\u003c/td\u003e\n","      \u003ctd\u003e0.169124\u003c/td\u003e\n","      \u003ctd\u003e17.277101\u003c/td\u003e\n","      \u003ctd\u003e0.171965\u003c/td\u003e\n","      \u003ctd\u003e32.050600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(2010, 2020)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e16.481524\u003c/td\u003e\n","      \u003ctd\u003e0.164606\u003c/td\u003e\n","      \u003ctd\u003e15.639564\u003c/td\u003e\n","      \u003ctd\u003e0.203521\u003c/td\u003e\n","      \u003ctd\u003e12.035303\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1960, 2020)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e17.564111\u003c/td\u003e\n","      \u003ctd\u003e0.161932\u003c/td\u003e\n","      \u003ctd\u003e17.326923\u003c/td\u003e\n","      \u003ctd\u003e0.169577\u003c/td\u003e\n","      \u003ctd\u003e43.612438\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(2000, 2009)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e17.855511\u003c/td\u003e\n","      \u003ctd\u003e0.161853\u003c/td\u003e\n","      \u003ctd\u003e18.087367\u003c/td\u003e\n","      \u003ctd\u003e0.160148\u003c/td\u003e\n","      \u003ctd\u003e11.979798\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1980, 1989)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e18.321210\u003c/td\u003e\n","      \u003ctd\u003e0.160942\u003c/td\u003e\n","      \u003ctd\u003e16.962868\u003c/td\u003e\n","      \u003ctd\u003e0.228245\u003c/td\u003e\n","      \u003ctd\u003e8.001913\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1960, 2020)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e17.601727\u003c/td\u003e\n","      \u003ctd\u003e0.157239\u003c/td\u003e\n","      \u003ctd\u003e17.707027\u003c/td\u003e\n","      \u003ctd\u003e0.152280\u003c/td\u003e\n","      \u003ctd\u003e47.586623\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(2000, 2009)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e18.394729\u003c/td\u003e\n","      \u003ctd\u003e0.147528\u003c/td\u003e\n","      \u003ctd\u003e16.997400\u003c/td\u003e\n","      \u003ctd\u003e0.205242\u003c/td\u003e\n","      \u003ctd\u003e21.803133\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1960, 2020)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e17.927970\u003c/td\u003e\n","      \u003ctd\u003e0.141619\u003c/td\u003e\n","      \u003ctd\u003e18.028353\u003c/td\u003e\n","      \u003ctd\u003e0.136897\u003c/td\u003e\n","      \u003ctd\u003e32.771489\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1990, 1999)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e18.738167\u003c/td\u003e\n","      \u003ctd\u003e0.134945\u003c/td\u003e\n","      \u003ctd\u003e17.128402\u003c/td\u003e\n","      \u003ctd\u003e0.215418\u003c/td\u003e\n","      \u003ctd\u003e11.502775\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(2010, 2020)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e17.107844\u003c/td\u003e\n","      \u003ctd\u003e0.131567\u003c/td\u003e\n","      \u003ctd\u003e16.918156\u003c/td\u003e\n","      \u003ctd\u003e0.139622\u003c/td\u003e\n","      \u003ctd\u003e11.017194\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1980, 1989)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.023107\u003c/td\u003e\n","      \u003ctd\u003e0.130575\u003c/td\u003e\n","      \u003ctd\u003e19.131860\u003c/td\u003e\n","      \u003ctd\u003e0.129141\u003c/td\u003e\n","      \u003ctd\u003e5.852744\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(2000, 2009)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e18.926655\u003c/td\u003e\n","      \u003ctd\u003e0.122877\u003c/td\u003e\n","      \u003ctd\u003e18.186654\u003c/td\u003e\n","      \u003ctd\u003e0.149635\u003c/td\u003e\n","      \u003ctd\u003e8.580507\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1980, 1989)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.168361\u003c/td\u003e\n","      \u003ctd\u003e0.122145\u003c/td\u003e\n","      \u003ctd\u003e18.919408\u003c/td\u003e\n","      \u003ctd\u003e0.139229\u003c/td\u003e\n","      \u003ctd\u003e3.006059\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1990, 1999)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.360811\u003c/td\u003e\n","      \u003ctd\u003e0.112333\u003c/td\u003e\n","      \u003ctd\u003e19.086334\u003c/td\u003e\n","      \u003ctd\u003e0.123587\u003c/td\u003e\n","      \u003ctd\u003e7.155642\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(2010, 2020)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e17.655426\u003c/td\u003e\n","      \u003ctd\u003e0.105105\u003c/td\u003e\n","      \u003ctd\u003e17.258658\u003c/td\u003e\n","      \u003ctd\u003e0.121066\u003c/td\u003e\n","      \u003ctd\u003e5.664942\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1960, 1969)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e17.872272\u003c/td\u003e\n","      \u003ctd\u003e0.102267\u003c/td\u003e\n","      \u003ctd\u003e17.853177\u003c/td\u003e\n","      \u003ctd\u003e0.109481\u003c/td\u003e\n","      \u003ctd\u003e4.133229\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1990, 1999)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.603721\u003c/td\u003e\n","      \u003ctd\u003e0.094987\u003c/td\u003e\n","      \u003ctd\u003e19.135066\u003c/td\u003e\n","      \u003ctd\u003e0.123501\u003c/td\u003e\n","      \u003ctd\u003e5.855078\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(2000, 2009)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.458995\u003c/td\u003e\n","      \u003ctd\u003e0.086585\u003c/td\u003e\n","      \u003ctd\u003e19.885427\u003c/td\u003e\n","      \u003ctd\u003e0.076659\u003c/td\u003e\n","      \u003ctd\u003e5.921247\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1970, 1979)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.309563\u003c/td\u003e\n","      \u003ctd\u003e0.081114\u003c/td\u003e\n","      \u003ctd\u003e17.837629\u003c/td\u003e\n","      \u003ctd\u003e0.151909\u003c/td\u003e\n","      \u003ctd\u003e11.427082\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(2010, 2020)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e18.279263\u003c/td\u003e\n","      \u003ctd\u003e0.072103\u003c/td\u003e\n","      \u003ctd\u003e17.961900\u003c/td\u003e\n","      \u003ctd\u003e0.086542\u003c/td\u003e\n","      \u003ctd\u003e9.024409\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1970, 1979)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.718265\u003c/td\u003e\n","      \u003ctd\u003e0.062102\u003c/td\u003e\n","      \u003ctd\u003e19.342401\u003c/td\u003e\n","      \u003ctd\u003e0.081506\u003c/td\u003e\n","      \u003ctd\u003e6.310778\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1990, 1999)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e20.540560\u003c/td\u003e\n","      \u003ctd\u003e0.058243\u003c/td\u003e\n","      \u003ctd\u003e20.458357\u003c/td\u003e\n","      \u003ctd\u003e0.060586\u003c/td\u003e\n","      \u003ctd\u003e2.438345\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1970, 1979)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.936048\u003c/td\u003e\n","      \u003ctd\u003e0.051743\u003c/td\u003e\n","      \u003ctd\u003e19.922251\u003c/td\u003e\n","      \u003ctd\u003e0.053972\u003c/td\u003e\n","      \u003ctd\u003e5.864005\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1970, 1979)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.932774\u003c/td\u003e\n","      \u003ctd\u003e0.051457\u003c/td\u003e\n","      \u003ctd\u003e19.480731\u003c/td\u003e\n","      \u003ctd\u003e0.073787\u003c/td\u003e\n","      \u003ctd\u003e2.991461\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1960, 1969)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e4 hidden layers (1024, 254, 128, 64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.209767\u003c/td\u003e\n","      \u003ctd\u003e0.034720\u003c/td\u003e\n","      \u003ctd\u003e19.460516\u003c/td\u003e\n","      \u003ctd\u003e0.026152\u003c/td\u003e\n","      \u003ctd\u003e5.829788\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003enew features\u003c/td\u003e\n","      \u003ctd\u003e(1960, 1969)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.331337\u003c/td\u003e\n","      \u003ctd\u003e0.028611\u003c/td\u003e\n","      \u003ctd\u003e19.292882\u003c/td\u003e\n","      \u003ctd\u003e0.034541\u003c/td\u003e\n","      \u003ctd\u003e6.352010\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003edeep learning\u003c/td\u003e\n","      \u003ctd\u003eall\u003c/td\u003e\n","      \u003ctd\u003estandard + new features\u003c/td\u003e\n","      \u003ctd\u003e(1960, 1969)\u003c/td\u003e\n","      \u003ctd\u003eMLP\u003c/td\u003e\n","      \u003ctd\u003e1 hidden layer (64)\u003c/td\u003e\n","      \u003ctd\u003eyear-weighted undersample\u003c/td\u003e\n","      \u003ctd\u003eregression\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003eNone\u003c/td\u003e\n","      \u003ctd\u003e19.541235\u003c/td\u003e\n","      \u003ctd\u003e0.018434\u003c/td\u003e\n","      \u003ctd\u003e19.291960\u003c/td\u003e\n","      \u003ctd\u003e0.037714\u003c/td\u003e\n","      \u003ctd\u003e4.288613\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["        category new_features_params  ...  train_r2   tot_time\n","0  deep learning                 all  ...  0.186282  11.464724\n","0  deep learning                 all  ...  0.171965  32.050600\n","0  deep learning                 all  ...  0.203521  12.035303\n","0  deep learning                 all  ...  0.169577  43.612438\n","0  deep learning                 all  ...  0.160148  11.979798\n","0  deep learning                 all  ...  0.228245   8.001913\n","0  deep learning                 all  ...  0.152280  47.586623\n","0  deep learning                 all  ...  0.205242  21.803133\n","0  deep learning                 all  ...  0.136897  32.771489\n","0  deep learning                 all  ...  0.215418  11.502775\n","0  deep learning                 all  ...  0.139622  11.017194\n","0  deep learning                 all  ...  0.129141   5.852744\n","0  deep learning                 all  ...  0.149635   8.580507\n","0  deep learning                 all  ...  0.139229   3.006059\n","0  deep learning                 all  ...  0.123587   7.155642\n","0  deep learning                 all  ...  0.121066   5.664942\n","0  deep learning                 all  ...  0.109481   4.133229\n","0  deep learning                 all  ...  0.123501   5.855078\n","0  deep learning                 all  ...  0.076659   5.921247\n","0  deep learning                 all  ...  0.151909  11.427082\n","0  deep learning                 all  ...  0.086542   9.024409\n","0  deep learning                 all  ...  0.081506   6.310778\n","0  deep learning                 all  ...  0.060586   2.438345\n","0  deep learning                 all  ...  0.053972   5.864005\n","0  deep learning                 all  ...  0.073787   2.991461\n","0  deep learning                 all  ...  0.026152   5.829788\n","0  deep learning                 all  ...  0.034541   6.352010\n","0  deep learning                 all  ...  0.037714   4.288613\n","\n","[28 rows x 31 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["df_tot.sort_values('test_r2', ascending=False).head(50)"]},{"cell_type":"markdown","metadata":{"id":"fjwAJYwemN1H"},"source":["# Export"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"phMigiMVlJuT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import  drive\n","\n","# mounts the google drive to Colab Notebook\n","drive.mount('/content/drive',force_remount=True)\n","\n","df_tot.to_csv('/content/drive/My Drive/Colab Notebooks/datasets/results_DL_4.1_'+str(x)+'_regression.csv')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOVBxjQU41Vkw3V/VfSN7ag","collapsed_sections":["VIbG3QskuKmv","733QnAej-lTM"],"name":"hit_song_prediction_DL_final_regression.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}